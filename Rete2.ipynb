{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ReteSA.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"bbQtZ5_2dahX","colab_type":"code","outputId":"2873d505-9120-4a11-fb0a-a4eac9ac0d16","executionInfo":{"status":"ok","timestamp":1563279988065,"user_tz":-120,"elapsed":30148,"user":{"displayName":"Manuel Verlengia","photoUrl":"","userId":"00922102153179523884"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"s2-XxXgAdeRf","colab_type":"code","outputId":"c38d2b1f-8811-45b7-aa9f-9776a3956053","executionInfo":{"status":"ok","timestamp":1563280029817,"user_tz":-120,"elapsed":44437,"user":{"displayName":"Manuel Verlengia","photoUrl":"","userId":"00922102153179523884"}},"colab":{"base_uri":"https://localhost:8080/","height":510}},"source":["!pip install tensorflow==1.12"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==1.12\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cc/ca70b78087015d21c5f3f93694107f34ebccb3be9624385a911d4b52ecef/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl (83.1MB)\n","\u001b[K     |████████████████████████████████| 83.1MB 349kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.16.4)\n","Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (0.7.1)\n","Collecting tensorboard<1.13.0,>=1.12.0 (from tensorflow==1.12)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/53/8d32ce9471c18f8d99028b7cef2e5b39ea8765bd7ef250ca05b490880971/tensorboard-1.12.2-py3-none-any.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.1MB 29.9MB/s \n","\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.15.0)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (0.2.2)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (3.7.1)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.1.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (0.33.4)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.1.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (0.8.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.12.0)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.0.8)\n","Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12) (0.15.4)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12) (3.1.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.12) (41.0.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.12) (2.8.0)\n","Installing collected packages: tensorboard, tensorflow\n","  Found existing installation: tensorboard 1.14.0\n","    Uninstalling tensorboard-1.14.0:\n","      Successfully uninstalled tensorboard-1.14.0\n","  Found existing installation: tensorflow 1.14.0\n","    Uninstalling tensorflow-1.14.0:\n","      Successfully uninstalled tensorflow-1.14.0\n","Successfully installed tensorboard-1.12.2 tensorflow-1.12.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_u7yNojcdgxw","colab_type":"code","colab":{}},"source":["import os\n","from io import BytesIO\n","from PIL import Image\n","\n","import cv2\n","import tensorflow as tf\n","\n","def del_all_flags(FLAGS):\n","    flags_dict = FLAGS._flags()    \n","    keys_list = [keys for keys in flags_dict]    \n","    for keys in keys_list:\n","        FLAGS.__delattr__(keys)\n","\n","del_all_flags(tf.flags.FLAGS)\n","\n","\n","FLAGS = tf.app.flags\n","FLAGS.DEFINE_string('data_dir',\n","                    '/content/gdrive/My Drive/datasetSA',\n","                    'Path to the input data')\n","FLAGS.DEFINE_string('train_output_path',\n","                    'train.tfrecord',\n","                    'Path to output train TFRecord')\n","FLAGS.DEFINE_string('eval_output_path',\n","                    'eval.tfrecord',\n","                    'Path to output eval TFRecord')\n","FLAGS.DEFINE_float(\n","    'train_eval_split_factor', 0.75,\n","    'use this factor to split the train (default 3/4) and '\n","    'eval data (default 1/4) in data_dir')\n","FLAGS.DEFINE_integer('width', 120, 'customize image width')\n","FLAGS.DEFINE_integer('height', 100, 'customize image height')\n","FLAGS.DEFINE_integer('channel', 3, 'image color channel')\n","FLAGS.DEFINE_integer('skip_frames', 10,\n","                     'the number of frames we skip when we process the video')\n","FLAGS.DEFINE_integer('num_frames_per_clip', 16,\n","                     'the number of frames for a video clip')\n","FLAGS = FLAGS.FLAGS\n","\n","\n","\n","def get_clips(image_list):\n","    # Given a list of images, return video clips of (num_frames_per_clip) consecutive frames as a list.\n","    video_clips = []\n","    images_len = len(image_list)\n","    if images_len < FLAGS.num_frames_per_clip:\n","        return video_clips\n","\n","    # Prepare the first clip\n","    video_clips.append(image_list[:FLAGS.num_frames_per_clip])\n","\n","    num_of_extra_clip = int(\n","        (images_len - FLAGS.num_frames_per_clip) / FLAGS.skip_frames)\n","    for i in range(1, num_of_extra_clip + 1):\n","        start = i * FLAGS.skip_frames - 1\n","        end = start + FLAGS.num_frames_per_clip\n","        video_clips.append(image_list[start:end])\n","\n","    return video_clips\n","\n","def process_dataset(train_writer, eval_writer, data_dir):\n","    label = 0\n","    # [class1, class2, class3, ..., class n]\n","    for class_dir in os.listdir(data_dir):\n","        class_path = os.path.join(data_dir, class_dir)\n","        if os.path.isdir(class_path):\n","            # Set the label value for this class, start from 0\n","            label += 1\n","            print(\"Processing class: \" + str(label))\n","            # Process each video file in this class\n","            video_filenames = os.listdir(class_path)\n","            for video_filename in video_filenames[0:int(\n","                    FLAGS.train_eval_split_factor * len(video_filenames))]:\n","                process_video(train_writer, class_path, video_filename, label)\n","            for video_filename in video_filenames[\n","                    int(FLAGS.train_eval_split_factor *\n","                        len(video_filenames)):len(video_filenames)]:\n","                process_video(eval_writer, class_path, video_filename, label)\n","\n","\n","def process_video(writer, class_path, video_filename, label):\n","    video_filename_path = os.path.join(class_path, video_filename)\n","    if video_filename_path.endswith('mp4'):\n","        video_clips = _convert_video_to_clips(video_filename_path)\n","        # Convert the clip to tf record\n","        for clip in video_clips:\n","            tf_example = create_tf_example(raw=clip, label=label)\n","            writer.write(tf_example.SerializeToString())\n","\n","\n","def _convert_video_to_clips(video_path):\n","    # Use opencv to read video to list of images\n","    video_images_list = []\n","    cap = cv2.VideoCapture(video_path)\n","    while cap.isOpened():\n","        # frame shape [height, width, channel]\n","        _, frame = cap.read()\n","        try:\n","            # pil_image shape [width, height, channel]\n","            pil_image = Image.fromarray(frame)\n","            # Resize the image and convert the image according to the channel information\n","            if FLAGS.channel == 1:\n","                pil_image = pil_image.resize((FLAGS.width, FLAGS.height),\n","                                             Image.NEAREST).convert('L')\n","            else:\n","                pil_image = pil_image.resize((FLAGS.width, FLAGS.height),\n","                                             Image.NEAREST)\n","            # Encode the image to JPEG\n","            with BytesIO() as buffer:\n","                pil_image.save(buffer, format=\"JPEG\")\n","                video_images_list.append(buffer.getvalue())\n","        except AttributeError:\n","            # Fail to read the image\n","            break\n","\n","    # Convert list of images to clips of images with type np.float32\n","    return get_clips(image_list=video_images_list)\n","\n","\n","def _bytelist_feature(value):\n","    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n","\n","\n","def _bytes_feature(value):\n","    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n","\n","\n","def _int64_feature(value):\n","    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n","\n","\n","def create_tf_example(raw, label):\n","    return tf.train.Example(\n","        features=tf.train.Features(\n","            feature={\n","                'clip/width': _int64_feature(FLAGS.width),\n","                'clip/height': _int64_feature(FLAGS.height),\n","                'clip/channel': _int64_feature(FLAGS.channel),\n","                'clip/raw': _bytelist_feature(raw),\n","                'clip/label': _int64_feature(label)\n","            }))\n","\n","\n","def get_total_video_clip_number(data_path):\n","    count = 0\n","    for _ in tf.python_io.tf_record_iterator(data_path):\n","        count += 1\n","    return count\n","\n","\n","def main(_):\n","    # Write the dataset\n","    train_writer = tf.python_io.TFRecordWriter(FLAGS.train_output_path)\n","    eval_writer = tf.python_io.TFRecordWriter(FLAGS.eval_output_path)\n","\n","    process_dataset(\n","        train_writer=train_writer,\n","        eval_writer=eval_writer,\n","        data_dir=FLAGS.data_dir)\n","\n","    train_writer.close()\n","    eval_writer.close()\n","\n","    # Count the dataset record\n","    print(\"Total clips in train dataset: \" +\n","          str(get_total_video_clip_number(FLAGS.train_output_path)))\n","    print(\"Total clips in eval dataset: \" +\n","          str(get_total_video_clip_number(FLAGS.eval_output_path)))\n","\n","\n","#if __name__ == '__main__':\n","#    tf.app.run()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4ttkMXyJdnCm","colab_type":"code","outputId":"457e6ff8-70c8-4a2d-d174-1d03755b85ce","executionInfo":{"status":"ok","timestamp":1563294972815,"user_tz":-120,"elapsed":6985818,"user":{"displayName":"Manuel Verlengia","photoUrl":"","userId":"00922102153179523884"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["class DenseNet3D(object):\n","    \"\"\"3D DenseNet Model class\"\"\"\n","\n","    def __init__(\n","            self,\n","            video_clips,  # Shape: [batch_size, sequence_length, height, width, channels]\n","            labels,  # Shape: [batch_size, num_classes] \n","            initial_learning_rate,\n","            decay_step,\n","            lr_decay_factor,\n","            num_classes,\n","            growth_rate,\n","            network_depth,\n","            total_blocks,\n","            keep_prob,\n","            weight_decay,\n","            reduction,\n","            bc_mode=False,\n","            **kwargs):\n","        self.video_clips = video_clips\n","        self.labels = labels\n","        self.num_classes = num_classes\n","        self.growth_rate = growth_rate\n","        self.network_depth = network_depth\n","\n","        # How many features will be received after first convolution value\n","        self.first_output_features = growth_rate * 2\n","\n","        self.total_blocks = total_blocks\n","        self.layers_per_block = (network_depth -\n","                                 (total_blocks + 1)) // total_blocks\n","\n","        # Compression rate at the transition layers\n","        self.reduction = reduction\n","        self.bc_mode = bc_mode\n","        if not bc_mode:\n","            self.reduction = 1.0\n","            print(\n","                \"Build 3D DenseNet model with %d blocks, %d composite layers each.\"\n","                % (total_blocks, self.layers_per_block))\n","\n","        if bc_mode:\n","            self.layers_per_block = self.layers_per_block // 2\n","            print(\n","                \"Build 3D DenseNet-BC model with %d blocks, %d bottleneck layers and %d composite layers each.\"\n","                % (total_blocks, self.layers_per_block, self.layers_per_block))\n","\n","        self.keep_prob = keep_prob\n","        self.weight_decay = weight_decay\n","        self._is_training = tf.convert_to_tensor(True)\n","\n","        # Initialize the global step\n","        self.global_step = tf.train.get_or_create_global_step()\n","\n","        self.learning_rate = tf.train.exponential_decay(\n","            initial_learning_rate,\n","            self.global_step,\n","            decay_step,\n","            lr_decay_factor,\n","            staircase=True)\n","\n","        self._build_graph()\n","\n","    def _build_graph(self):\n","        # First convolution layer\n","        with tf.variable_scope('Initial_convolution'):\n","            output = self._conv3d(\n","                self.video_clips,\n","                out_features_count=self.first_output_features,\n","                kernel_size=7,\n","                strides=[1, 1, 2, 2, 1])\n","            output = self._pool(output, k=3, d=2, k_stride=2, d_stride=1)\n","\n","        # Add 3D DenseNet blocks\n","        for block in range(self.total_blocks):\n","            with tf.variable_scope(\"Block_%d\" % block):\n","                output = self._add_block(output, self.growth_rate,\n","                                         self.layers_per_block)\n","            # The last block exist without transition layer\n","            if block != self.total_blocks - 1:\n","                with tf.variable_scope(\"Transition_after_block_%d\" % block):\n","                    output = self._transition_layer(output, pool_depth=2)\n","\n","        # Fully connected layers\n","        with tf.variable_scope('Transition_to_classes'):\n","            self._logits = self._trainsition_layer_to_classes(output)\n","\n","        # Prediction result\n","        self._prediction = tf.argmax(self._logits, 1)\n","\n","        # Losses\n","        self._cross_entropy = tf.reduce_mean(\n","            tf.nn.sparse_softmax_cross_entropy_with_logits(\n","                logits=self._logits, labels=self.labels),\n","            name='Cross_entropy')\n","        self.l2_loss = tf.add_n(\n","            [tf.nn.l2_loss(var) for var in tf.trainable_variables()])\n","        self.total_loss = self._cross_entropy + self.l2_loss * self.weight_decay\n","\n","        # Optimizer and training op\n","        self._train_op = tf.contrib.layers.optimize_loss(\n","            loss=self.total_loss,\n","            global_step=self.global_step,\n","            learning_rate=self.learning_rate,\n","            optimizer='Momentum')\n","\n","    @property\n","    def logits(self):\n","        return self._logits\n","\n","    @property\n","    def train_op(self):\n","        return self._train_op\n","\n","    @property\n","    def losses(self):\n","        return self._cross_entropy\n","\n","    @property\n","    def prediction(self):\n","        return self._prediction\n","\n","    @property\n","    def accuracy(self):\n","        correct_prediction = tf.equal(tf.argmax(self._logits, 1), self.labels)\n","        return tf.metrics.mean(tf.cast(correct_prediction, tf.float32))\n","\n","    @property\n","    def is_training(self):\n","        return self._is_training\n","\n","    @is_training.setter\n","    def is_training(self, value):\n","        self._is_training = tf.convert_to_tensor(value)\n","\n","    def _conv3d(self,\n","                inputs,\n","                out_features_count,\n","                kernel_size,\n","                strides=[1, 1, 1, 1, 1],\n","                padding='SAME'):\n","        input_features_count = int(inputs.get_shape()[-1])\n","        kernel = tf.get_variable(\n","            'kernel',\n","            shape=[\n","                kernel_size, kernel_size, kernel_size, input_features_count,\n","                out_features_count\n","            ],\n","            initializer=tf.random_normal_initializer())\n","        with tf.name_scope('3d_conv'):\n","            return tf.nn.conv3d(\n","                inputs, filter=kernel, strides=strides, padding=padding)\n","\n","    def _pool(self,\n","              inputs,\n","              k,\n","              d=2,\n","              k_stride=None,\n","              d_stride=None,\n","              width_k=None,\n","              k_stride_width=None):\n","        if not width_k:\n","            width_k = k\n","        kernel_size = [1, d, k, width_k, 1]\n","        if not k_stride:\n","            k_stride = k\n","        if not k_stride_width:\n","            k_stride_width = k_stride\n","        if not d_stride:\n","            d_stride = d\n","        strides = [1, d_stride, k_stride, k_stride_width, 1]\n","        return tf.nn.max_pool3d(\n","            inputs, ksize=kernel_size, strides=strides, padding='SAME')\n","\n","    def _add_block(self, inputs, growth_rate, layers_per_block):\n","        for layer in range(layers_per_block):\n","            with tf.variable_scope(\"layer_%d\" % layer):\n","                return self._add_internal_layer(inputs, growth_rate)\n","\n","    def _add_internal_layer(self, inputs, growth_rate):\n","        if not self.bc_mode:\n","            composite_out = self._composite_function(\n","                inputs, out_features_count=growth_rate, kernel_size=3)\n","        elif self.bc_mode:\n","            bottleneck_out = self._bottleneck(\n","                inputs, out_features_count=growth_rate)\n","            composite_out = self._composite_function(\n","                bottleneck_out, out_features_count=growth_rate, kernel_size=3)\n","\n","        with tf.name_scope('concat'):\n","            return tf.concat(axis=4, values=(inputs, composite_out))\n","\n","    def _composite_function(self, inputs, out_features_count, kernel_size):\n","        with tf.variable_scope('composite_function'):\n","            # Batch normalization\n","            output = self._batch_norm(inputs)\n","            # ReLU\n","            with tf.name_scope('ReLU'):\n","                output = tf.nn.relu(output)\n","            # Convolution\n","            output = self._conv3d(\n","                output,\n","                out_features_count=out_features_count,\n","                kernel_size=kernel_size)\n","            # Dropout\n","            output = self._dropout(output)\n","        return output\n","\n","    def _bottleneck(self, inputs, out_features_count):\n","        with tf.variable_scope('bottleneck'):\n","            # Batch normalization\n","            output = self._batch_norm(inputs)\n","            # ReLU\n","            with tf.name_scope('ReLU'):\n","                output = tf.nn.relu(output)\n","\n","            inter_features = out_features_count * 4\n","            output = self._conv3d(\n","                output,\n","                out_features_count=inter_features,\n","                kernel_size=1,\n","                padding='VALID')\n","            output = self._dropout(output)\n","        return output\n","\n","    def _batch_norm(self, inputs):\n","        with tf.name_scope('batch_normalization'):\n","            output = tf.contrib.layers.batch_norm(\n","                inputs,\n","                scale=True,\n","                is_training=self._is_training,\n","                updates_collections=None)\n","        return output\n","\n","    def _dropout(self, inputs):\n","        if self.keep_prob < 1:\n","            with tf.name_scope('dropout'):\n","                output = tf.cond(self._is_training,\n","                                 lambda: tf.nn.dropout(inputs, self.keep_prob),\n","                                 lambda: inputs)\n","        else:\n","            output = inputs\n","        return output\n","\n","    def _transition_layer(self, inputs, pool_depth):\n","        out_features_count = int(int(inputs.get_shape()[-1]) * self.reduction)\n","        output = self._composite_function(\n","            inputs, out_features_count=out_features_count, kernel_size=1)\n","        with tf.name_scope('pooling'):\n","            output = self._pool(output, k=2, d=pool_depth)\n","        return output\n","\n","    def _trainsition_layer_to_classes(self, inputs):\n","        # Batch normalization\n","        output = self._batch_norm(inputs)\n","        # ReLU\n","        with tf.name_scope('ReLU'):\n","            output = tf.nn.relu(output)\n","        # pooling\n","        last_pool_kernel_width = int(output.get_shape()[-2])\n","        last_pool_kernel_height = int(output.get_shape()[-3])\n","        last_sequence_length = int(output.get_shape()[1])\n","        with tf.name_scope('pooling'):\n","            output = self._pool(\n","                output,\n","                k=last_pool_kernel_height,\n","                d=last_sequence_length,\n","                width_k=last_pool_kernel_width,\n","                k_stride_width=last_pool_kernel_width)\n","        # Fully connected\n","        features_total = int(output.get_shape()[-1])\n","        output = tf.reshape(output, [-1, features_total])\n","        weight = tf.get_variable(\n","            'fc_w',\n","            shape=[features_total, self.num_classes],\n","            initializer=tf.contrib.layers.xavier_initializer())\n","        bias = tf.get_variable(\n","            'fc_bias',\n","            shape=[self.num_classes],\n","            initializer=tf.zeros_initializer())\n","        logits = tf.matmul(output, weight) + bias\n","        return logits\n","\n","def model_fn(features, labels, mode, params):\n","    # Define the model\n","    model = DenseNet3D(\n","        video_clips=features['video_clips'], labels=labels, **params)\n","\n","    # Get the prediction result\n","    if mode == tf.estimator.ModeKeys.PREDICT:\n","        model.is_training = False\n","        return _predict_result(model.logits)\n","\n","    return tf.estimator.EstimatorSpec(\n","        mode=mode,\n","        loss=model.losses,\n","        train_op=model.train_op,\n","        eval_metric_ops={'eval_accuracy': model.accuracy})\n","\n","\n","def _predict_result(model):\n","    predictions = {'probabilities': model.prediction, 'logits': model.logits}\n","    return tf.estimator.EstimatorSpec(\n","        mode=tf.estimator.ModeKeys.PREDICT, predictions=predictions)\n","\n","\n","def serving_input_fn(params):\n","    inputs = {\n","        'video_clips':\n","        tf.placeholder(\n","            tf.float32,\n","            shape=[\n","                None, params['num_frames_per_clip'], params['height'],\n","                params['width'], params['channel']\n","            ])\n","    }\n","    return tf.estimator.export.build_raw_serving_input_receiver_fn(inputs)()\n","\n","\n","def train_input_fn(training_dir, params):\n","    directory = os.path.join(training_dir, 'train.tfrecord')\n","    return _build_tfrecord_dataset(directory, params['train_total_video_clip'],\n","                                   **params)\n","\n","\n","def eval_input_fn(evaluating_dir, params):\n","    directory = os.path.join(evaluating_dir, 'eval.tfrecord')\n","    return _build_tfrecord_dataset(directory, params['eval_total_video_clip'],\n","                                   **params)\n","\n","\n","def _build_tfrecord_dataset(directory, total_clip_num, batch_size, **params):\n","    '''\n","    Buffer the training dataset to TFRecordDataset with the following video shape\n","    [num_frames_per_clip, height, width, channel]\n","    ex: [16, 100, 120, 3]\n","    '''\n","    dataset = tf.data.TFRecordDataset(directory)\n","    dataset = dataset.shuffle(buffer_size=total_clip_num)\n","    dataset = dataset.map(\n","        map_func=\n","        lambda serialized_example: _parser(serialized_example, **params))\n","    dataset = dataset.repeat()\n","    iterator = dataset.batch(batch_size=batch_size).make_one_shot_iterator()\n","    clips, labels = iterator.get_next()\n","    return {'video_clips': clips}, labels\n","\n","\n","def _parser(serialized_example, num_frames_per_clip, **params):\n","    features = tf.parse_single_example(\n","        serialized_example,\n","        features={\n","            'clip/width': tf.FixedLenFeature([], tf.int64),\n","            'clip/height': tf.FixedLenFeature([], tf.int64),\n","            'clip/channel': tf.FixedLenFeature([], tf.int64),\n","            'clip/raw': tf.FixedLenFeature([num_frames_per_clip], tf.string),\n","            'clip/label': tf.FixedLenFeature([], tf.int64)\n","        })\n","\n","    def mapping_func(image):\n","        return _decode_image(image, **params)\n","\n","    clip = tf.map_fn(mapping_func, features['clip/raw'], dtype=tf.float32)\n","    return clip, features['clip/label']\n","\n","\n","def _decode_image(image, channel, width, height, **params):\n","    image = tf.image.decode_jpeg(image, channels=channel)\n","    # This set_shape step is necesary for the last trainsition_layer_to_classes layer in the model\n","    image.set_shape([height, width, channel])\n","    image = tf.cast(image, tf.float32)\n","    return image\n","\n","\"\"\"This is the main class\"\"\"\n","\n","\n","MODEL_DIR = 'denseNet3d_result'\n","DATA_DIR = '/content'\n","\n","HYPERPARAMETERS = {\n","    'num_classes': 6,  # The number of the classes that this dataset had\n","    'batch_size': 20,\n","    'initial_learning_rate': 0.1,\n","    'decay_step': 5000,\n","    'lr_decay_factor':\n","    0.1,  # Learning rate will decay by a factor for every decay_step\n","    'growth_rate': 12,  # Grows rate for every layer [12, 24, 40]\n","    'network_depth': 20,  # Depth of the whole network [20, 40, 250]\n","    'total_blocks': 3,  # Total blocks of layers stack\n","    'keep_prob': 0.9,  # Keep probability for dropout\n","    'weight_decay': 1e-4,  # Weight decay for L2 loss\n","    'model_type': 'DenseNet3D',\n","    'reduction': 0.5,  # Reduction rate at transition layer for the models\n","    'bc_mode': True,\n","    'num_frames_per_clip': 16,  # The length of the video clip\n","    'width': 120,\n","    'height': 100,\n","    'channel': 3,\n","    'train_total_video_clip': 4183,\n","    'eval_total_video_clip': 914\n","}\n","\n","TFRUNCONFIG = tf.estimator.RunConfig(\n","    log_step_count_steps=1, save_summary_steps=1, model_dir=MODEL_DIR)\n","\n","CLASSIFIER = tf.estimator.Estimator(\n","    model_fn=model_fn, params=HYPERPARAMETERS, config=TFRUNCONFIG)\n","\n","CLASSIFIER.train(\n","    input_fn=lambda: train_input_fn(DATA_DIR, HYPERPARAMETERS),\n","    steps=210)\n","\n","CLASSIFIER.evaluate(\n","    input_fn=lambda: eval_input_fn(DATA_DIR, HYPERPARAMETERS),\n","    steps=45)\n","\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Using config: {'_model_dir': 'denseNet3d_result', '_tf_random_seed': None, '_save_summary_steps': 1, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7eff020b3160>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","INFO:tensorflow:Calling model_fn.\n","Build 3D DenseNet-BC model with 3 blocks, 2 bottleneck layers and 2 composite layers each.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from denseNet3d_result/model.ckpt-4410\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Saving checkpoints for 4410 into denseNet3d_result/model.ckpt.\n","INFO:tensorflow:loss = 2.5134673, step = 4411\n","INFO:tensorflow:global_step/sec: 0.0319346\n","INFO:tensorflow:loss = 1.6259658, step = 4412 (31.316 sec)\n","INFO:tensorflow:global_step/sec: 0.0319552\n","INFO:tensorflow:loss = 1.2848737, step = 4413 (31.294 sec)\n","INFO:tensorflow:global_step/sec: 0.0320521\n","INFO:tensorflow:loss = 1.2931924, step = 4414 (31.199 sec)\n","INFO:tensorflow:global_step/sec: 0.0325183\n","INFO:tensorflow:loss = 1.7402767, step = 4415 (30.751 sec)\n","INFO:tensorflow:global_step/sec: 0.0323062\n","INFO:tensorflow:loss = 1.328768, step = 4416 (30.954 sec)\n","INFO:tensorflow:global_step/sec: 0.032422\n","INFO:tensorflow:loss = 1.2717308, step = 4417 (30.843 sec)\n","INFO:tensorflow:global_step/sec: 0.0322252\n","INFO:tensorflow:loss = 1.5272111, step = 4418 (31.032 sec)\n","INFO:tensorflow:global_step/sec: 0.0322926\n","INFO:tensorflow:loss = 1.2828025, step = 4419 (30.966 sec)\n","INFO:tensorflow:global_step/sec: 0.032707\n","INFO:tensorflow:loss = 1.5992235, step = 4420 (30.574 sec)\n","INFO:tensorflow:global_step/sec: 0.0325382\n","INFO:tensorflow:loss = 1.4874227, step = 4421 (30.733 sec)\n","INFO:tensorflow:global_step/sec: 0.0324039\n","INFO:tensorflow:loss = 1.4949074, step = 4422 (30.861 sec)\n","INFO:tensorflow:global_step/sec: 0.032122\n","INFO:tensorflow:loss = 1.4644015, step = 4423 (31.131 sec)\n","INFO:tensorflow:global_step/sec: 0.0323384\n","INFO:tensorflow:loss = 1.2454231, step = 4424 (30.923 sec)\n","INFO:tensorflow:global_step/sec: 0.0323461\n","INFO:tensorflow:loss = 1.3193705, step = 4425 (30.916 sec)\n","INFO:tensorflow:global_step/sec: 0.0321049\n","INFO:tensorflow:loss = 1.4955355, step = 4426 (31.148 sec)\n","INFO:tensorflow:global_step/sec: 0.0322631\n","INFO:tensorflow:loss = 1.3461882, step = 4427 (30.995 sec)\n","INFO:tensorflow:global_step/sec: 0.0324795\n","INFO:tensorflow:loss = 1.2368133, step = 4428 (30.788 sec)\n","INFO:tensorflow:global_step/sec: 0.0325204\n","INFO:tensorflow:loss = 1.293107, step = 4429 (30.750 sec)\n","INFO:tensorflow:Saving checkpoints for 4430 into denseNet3d_result/model.ckpt.\n","INFO:tensorflow:global_step/sec: 0.0323116\n","INFO:tensorflow:loss = 1.2189999, step = 4430 (30.950 sec)\n","INFO:tensorflow:global_step/sec: 0.0326037\n","INFO:tensorflow:loss = 1.2343585, step = 4431 (30.671 sec)\n","INFO:tensorflow:global_step/sec: 0.0324077\n","INFO:tensorflow:loss = 1.2873634, step = 4432 (30.856 sec)\n","INFO:tensorflow:global_step/sec: 0.0323728\n","INFO:tensorflow:loss = 1.0023378, step = 4433 (30.890 sec)\n","INFO:tensorflow:global_step/sec: 0.0324035\n","INFO:tensorflow:loss = 1.2225943, step = 4434 (30.861 sec)\n","INFO:tensorflow:global_step/sec: 0.032403\n","INFO:tensorflow:loss = 1.2743342, step = 4435 (30.861 sec)\n","INFO:tensorflow:global_step/sec: 0.0327154\n","INFO:tensorflow:loss = 1.3236421, step = 4436 (30.567 sec)\n","INFO:tensorflow:global_step/sec: 0.0327556\n","INFO:tensorflow:loss = 1.2101912, step = 4437 (30.529 sec)\n","INFO:tensorflow:global_step/sec: 0.032229\n","INFO:tensorflow:loss = 1.4534419, step = 4438 (31.028 sec)\n","INFO:tensorflow:global_step/sec: 0.0324577\n","INFO:tensorflow:loss = 1.1664774, step = 4439 (30.813 sec)\n","INFO:tensorflow:global_step/sec: 0.032567\n","INFO:tensorflow:loss = 1.40115, step = 4440 (30.702 sec)\n","INFO:tensorflow:global_step/sec: 0.032428\n","INFO:tensorflow:loss = 1.2893722, step = 4441 (30.838 sec)\n","INFO:tensorflow:global_step/sec: 0.032037\n","INFO:tensorflow:loss = 1.0784307, step = 4442 (31.214 sec)\n","INFO:tensorflow:global_step/sec: 0.0319904\n","INFO:tensorflow:loss = 1.3732964, step = 4443 (31.259 sec)\n","INFO:tensorflow:global_step/sec: 0.0321568\n","INFO:tensorflow:loss = 0.8689454, step = 4444 (31.098 sec)\n","INFO:tensorflow:global_step/sec: 0.0323324\n","INFO:tensorflow:loss = 1.4012346, step = 4445 (30.929 sec)\n","INFO:tensorflow:global_step/sec: 0.032426\n","INFO:tensorflow:loss = 1.0965106, step = 4446 (30.840 sec)\n","INFO:tensorflow:global_step/sec: 0.0325369\n","INFO:tensorflow:loss = 1.2143853, step = 4447 (30.733 sec)\n","INFO:tensorflow:global_step/sec: 0.0324843\n","INFO:tensorflow:loss = 1.286697, step = 4448 (30.784 sec)\n","INFO:tensorflow:global_step/sec: 0.0324321\n","INFO:tensorflow:loss = 1.01071, step = 4449 (30.834 sec)\n","INFO:tensorflow:Saving checkpoints for 4450 into denseNet3d_result/model.ckpt.\n","INFO:tensorflow:global_step/sec: 0.0323228\n","INFO:tensorflow:loss = 1.0326346, step = 4450 (30.938 sec)\n","INFO:tensorflow:global_step/sec: 0.0323069\n","INFO:tensorflow:loss = 1.1184676, step = 4451 (30.953 sec)\n","INFO:tensorflow:global_step/sec: 0.0324581\n","INFO:tensorflow:loss = 1.0471216, step = 4452 (30.813 sec)\n","INFO:tensorflow:global_step/sec: 0.0325098\n","INFO:tensorflow:loss = 1.45281, step = 4453 (30.760 sec)\n","INFO:tensorflow:global_step/sec: 0.0325276\n","INFO:tensorflow:loss = 1.4479809, step = 4454 (30.739 sec)\n","INFO:tensorflow:global_step/sec: 0.0325504\n","INFO:tensorflow:loss = 1.724371, step = 4455 (30.723 sec)\n","INFO:tensorflow:global_step/sec: 0.0326343\n","INFO:tensorflow:loss = 1.4382033, step = 4456 (30.640 sec)\n","INFO:tensorflow:global_step/sec: 0.0327168\n","INFO:tensorflow:loss = 1.3422673, step = 4457 (30.565 sec)\n","INFO:tensorflow:global_step/sec: 0.033347\n","INFO:tensorflow:loss = 1.3843247, step = 4458 (29.988 sec)\n","INFO:tensorflow:global_step/sec: 0.0328764\n","INFO:tensorflow:loss = 1.4516361, step = 4459 (30.417 sec)\n","INFO:tensorflow:global_step/sec: 0.0325091\n","INFO:tensorflow:loss = 0.9841776, step = 4460 (30.761 sec)\n","INFO:tensorflow:global_step/sec: 0.0324896\n","INFO:tensorflow:loss = 0.9432624, step = 4461 (30.779 sec)\n","INFO:tensorflow:global_step/sec: 0.0322026\n","INFO:tensorflow:loss = 1.1587574, step = 4462 (31.054 sec)\n","INFO:tensorflow:global_step/sec: 0.0322254\n","INFO:tensorflow:loss = 1.2211589, step = 4463 (31.031 sec)\n","INFO:tensorflow:global_step/sec: 0.0321778\n","INFO:tensorflow:loss = 1.1543287, step = 4464 (31.077 sec)\n","INFO:tensorflow:global_step/sec: 0.0322396\n","INFO:tensorflow:loss = 1.1978658, step = 4465 (31.018 sec)\n","INFO:tensorflow:global_step/sec: 0.0323825\n","INFO:tensorflow:loss = 1.1483704, step = 4466 (30.881 sec)\n","INFO:tensorflow:global_step/sec: 0.0321292\n","INFO:tensorflow:loss = 1.0783596, step = 4467 (31.124 sec)\n","INFO:tensorflow:global_step/sec: 0.0324398\n","INFO:tensorflow:loss = 1.290272, step = 4468 (30.827 sec)\n","INFO:tensorflow:global_step/sec: 0.032271\n","INFO:tensorflow:loss = 1.0465138, step = 4469 (30.987 sec)\n","INFO:tensorflow:Saving checkpoints for 4470 into denseNet3d_result/model.ckpt.\n","INFO:tensorflow:global_step/sec: 0.0321922\n","INFO:tensorflow:loss = 1.4653537, step = 4470 (31.066 sec)\n","INFO:tensorflow:global_step/sec: 0.0321264\n","INFO:tensorflow:loss = 1.2201439, step = 4471 (31.124 sec)\n","INFO:tensorflow:global_step/sec: 0.0323321\n","INFO:tensorflow:loss = 1.2684782, step = 4472 (30.929 sec)\n","INFO:tensorflow:global_step/sec: 0.0323007\n","INFO:tensorflow:loss = 1.1241844, step = 4473 (30.959 sec)\n","INFO:tensorflow:global_step/sec: 0.0323419\n","INFO:tensorflow:loss = 1.0106544, step = 4474 (30.922 sec)\n","INFO:tensorflow:global_step/sec: 0.0325179\n","INFO:tensorflow:loss = 1.1183028, step = 4475 (30.750 sec)\n","INFO:tensorflow:global_step/sec: 0.0325651\n","INFO:tensorflow:loss = 1.4261853, step = 4476 (30.707 sec)\n","INFO:tensorflow:global_step/sec: 0.0324258\n","INFO:tensorflow:loss = 0.8936202, step = 4477 (30.840 sec)\n","INFO:tensorflow:global_step/sec: 0.0325707\n","INFO:tensorflow:loss = 1.085613, step = 4478 (30.703 sec)\n","INFO:tensorflow:global_step/sec: 0.0325328\n","INFO:tensorflow:loss = 1.4960423, step = 4479 (30.739 sec)\n","INFO:tensorflow:global_step/sec: 0.0327508\n","INFO:tensorflow:loss = 1.4286406, step = 4480 (30.532 sec)\n","INFO:tensorflow:global_step/sec: 0.0324824\n","INFO:tensorflow:loss = 1.2642382, step = 4481 (30.786 sec)\n","INFO:tensorflow:global_step/sec: 0.0326658\n","INFO:tensorflow:loss = 1.1338631, step = 4482 (30.613 sec)\n","INFO:tensorflow:global_step/sec: 0.032544\n","INFO:tensorflow:loss = 1.1120303, step = 4483 (30.727 sec)\n","INFO:tensorflow:global_step/sec: 0.0321067\n","INFO:tensorflow:loss = 1.1962091, step = 4484 (31.146 sec)\n","INFO:tensorflow:global_step/sec: 0.0323173\n","INFO:tensorflow:loss = 1.3072857, step = 4485 (30.944 sec)\n","INFO:tensorflow:global_step/sec: 0.0324249\n","INFO:tensorflow:loss = 1.2044208, step = 4486 (30.840 sec)\n","INFO:tensorflow:global_step/sec: 0.0325949\n","INFO:tensorflow:loss = 0.86666965, step = 4487 (30.680 sec)\n","INFO:tensorflow:global_step/sec: 0.0326287\n","INFO:tensorflow:loss = 1.3568211, step = 4488 (30.647 sec)\n","INFO:tensorflow:global_step/sec: 0.0326285\n","INFO:tensorflow:loss = 1.4226931, step = 4489 (30.648 sec)\n","INFO:tensorflow:Saving checkpoints for 4490 into denseNet3d_result/model.ckpt.\n","INFO:tensorflow:global_step/sec: 0.032766\n","INFO:tensorflow:loss = 1.1929477, step = 4490 (30.520 sec)\n","INFO:tensorflow:global_step/sec: 0.0324788\n","INFO:tensorflow:loss = 1.5196017, step = 4491 (30.790 sec)\n","INFO:tensorflow:global_step/sec: 0.0323569\n","INFO:tensorflow:loss = 1.5127499, step = 4492 (30.909 sec)\n","INFO:tensorflow:global_step/sec: 0.0325632\n","INFO:tensorflow:loss = 0.9703743, step = 4493 (30.705 sec)\n","INFO:tensorflow:global_step/sec: 0.032624\n","INFO:tensorflow:loss = 0.9990381, step = 4494 (30.652 sec)\n","INFO:tensorflow:global_step/sec: 0.0326517\n","INFO:tensorflow:loss = 1.29628, step = 4495 (30.626 sec)\n","INFO:tensorflow:global_step/sec: 0.0326053\n","INFO:tensorflow:loss = 1.2822758, step = 4496 (30.669 sec)\n","INFO:tensorflow:global_step/sec: 0.032159\n","INFO:tensorflow:loss = 1.096014, step = 4497 (31.096 sec)\n","INFO:tensorflow:global_step/sec: 0.0323726\n","INFO:tensorflow:loss = 0.98222464, step = 4498 (30.890 sec)\n","INFO:tensorflow:global_step/sec: 0.032303\n","INFO:tensorflow:loss = 1.0855736, step = 4499 (30.957 sec)\n","INFO:tensorflow:global_step/sec: 0.0324885\n","INFO:tensorflow:loss = 1.3313328, step = 4500 (30.780 sec)\n","INFO:tensorflow:global_step/sec: 0.0326819\n","INFO:tensorflow:loss = 1.3450363, step = 4501 (30.598 sec)\n","INFO:tensorflow:global_step/sec: 0.0321798\n","INFO:tensorflow:loss = 0.8899659, step = 4502 (31.076 sec)\n","INFO:tensorflow:global_step/sec: 0.032309\n","INFO:tensorflow:loss = 1.010534, step = 4503 (30.951 sec)\n","INFO:tensorflow:global_step/sec: 0.0321961\n","INFO:tensorflow:loss = 1.2484527, step = 4504 (31.060 sec)\n","INFO:tensorflow:global_step/sec: 0.0322456\n","INFO:tensorflow:loss = 1.4959692, step = 4505 (31.012 sec)\n","INFO:tensorflow:global_step/sec: 0.03226\n","INFO:tensorflow:loss = 1.1935706, step = 4506 (30.999 sec)\n","INFO:tensorflow:global_step/sec: 0.0323957\n","INFO:tensorflow:loss = 0.993756, step = 4507 (30.868 sec)\n","INFO:tensorflow:global_step/sec: 0.032347\n","INFO:tensorflow:loss = 1.156497, step = 4508 (30.916 sec)\n","INFO:tensorflow:global_step/sec: 0.0323589\n","INFO:tensorflow:loss = 1.2181093, step = 4509 (30.903 sec)\n","INFO:tensorflow:Saving checkpoints for 4510 into denseNet3d_result/model.ckpt.\n","INFO:tensorflow:global_step/sec: 0.0323256\n","INFO:tensorflow:loss = 1.264011, step = 4510 (30.935 sec)\n","INFO:tensorflow:global_step/sec: 0.0322778\n","INFO:tensorflow:loss = 1.2157687, step = 4511 (30.982 sec)\n","INFO:tensorflow:global_step/sec: 0.0322617\n","INFO:tensorflow:loss = 1.1046687, step = 4512 (30.999 sec)\n","INFO:tensorflow:global_step/sec: 0.0323482\n","INFO:tensorflow:loss = 1.3848288, step = 4513 (30.911 sec)\n","INFO:tensorflow:global_step/sec: 0.0322309\n","INFO:tensorflow:loss = 1.0323293, step = 4514 (31.029 sec)\n","INFO:tensorflow:global_step/sec: 0.0325256\n","INFO:tensorflow:loss = 1.0585732, step = 4515 (30.747 sec)\n","INFO:tensorflow:global_step/sec: 0.0322092\n","INFO:tensorflow:loss = 1.172484, step = 4516 (31.046 sec)\n","INFO:tensorflow:global_step/sec: 0.0321446\n","INFO:tensorflow:loss = 0.9650794, step = 4517 (31.105 sec)\n","INFO:tensorflow:global_step/sec: 0.0320475\n","INFO:tensorflow:loss = 1.1502882, step = 4518 (31.204 sec)\n","INFO:tensorflow:global_step/sec: 0.0322344\n","INFO:tensorflow:loss = 1.3738159, step = 4519 (31.022 sec)\n","INFO:tensorflow:global_step/sec: 0.0323549\n","INFO:tensorflow:loss = 1.0395725, step = 4520 (30.907 sec)\n","INFO:tensorflow:global_step/sec: 0.0321422\n","INFO:tensorflow:loss = 0.90970373, step = 4521 (31.116 sec)\n","INFO:tensorflow:global_step/sec: 0.0321038\n","INFO:tensorflow:loss = 1.3281481, step = 4522 (31.149 sec)\n","INFO:tensorflow:global_step/sec: 0.032113\n","INFO:tensorflow:loss = 0.9089111, step = 4523 (31.135 sec)\n","INFO:tensorflow:global_step/sec: 0.0322008\n","INFO:tensorflow:loss = 1.2535046, step = 4524 (31.055 sec)\n","INFO:tensorflow:global_step/sec: 0.0325471\n","INFO:tensorflow:loss = 0.902129, step = 4525 (30.725 sec)\n","INFO:tensorflow:global_step/sec: 0.0323239\n","INFO:tensorflow:loss = 1.4317956, step = 4526 (30.937 sec)\n","INFO:tensorflow:global_step/sec: 0.0324356\n","INFO:tensorflow:loss = 1.0713599, step = 4527 (30.830 sec)\n","INFO:tensorflow:global_step/sec: 0.0324228\n","INFO:tensorflow:loss = 1.2946136, step = 4528 (30.845 sec)\n","INFO:tensorflow:global_step/sec: 0.0324091\n","INFO:tensorflow:loss = 1.1457083, step = 4529 (30.853 sec)\n","INFO:tensorflow:Saving checkpoints for 4530 into denseNet3d_result/model.ckpt.\n","INFO:tensorflow:global_step/sec: 0.0321002\n","INFO:tensorflow:loss = 1.3831443, step = 4530 (31.153 sec)\n","INFO:tensorflow:global_step/sec: 0.0324765\n","INFO:tensorflow:loss = 1.3499415, step = 4531 (30.794 sec)\n","INFO:tensorflow:global_step/sec: 0.0325483\n","INFO:tensorflow:loss = 1.3163092, step = 4532 (30.721 sec)\n","INFO:tensorflow:global_step/sec: 0.0324996\n","INFO:tensorflow:loss = 1.2955191, step = 4533 (30.769 sec)\n","INFO:tensorflow:global_step/sec: 0.0323262\n","INFO:tensorflow:loss = 0.9652054, step = 4534 (30.935 sec)\n","INFO:tensorflow:global_step/sec: 0.032739\n","INFO:tensorflow:loss = 1.2033522, step = 4535 (30.545 sec)\n","INFO:tensorflow:global_step/sec: 0.0328741\n","INFO:tensorflow:loss = 1.2819107, step = 4536 (30.419 sec)\n","INFO:tensorflow:global_step/sec: 0.0328569\n","INFO:tensorflow:loss = 1.1688201, step = 4537 (30.435 sec)\n","INFO:tensorflow:global_step/sec: 0.0328448\n","INFO:tensorflow:loss = 1.3317701, step = 4538 (30.450 sec)\n","INFO:tensorflow:global_step/sec: 0.0328111\n","INFO:tensorflow:loss = 0.9243101, step = 4539 (30.474 sec)\n","INFO:tensorflow:global_step/sec: 0.0326835\n","INFO:tensorflow:loss = 0.9974864, step = 4540 (30.597 sec)\n","INFO:tensorflow:global_step/sec: 0.0326681\n","INFO:tensorflow:loss = 1.5103706, step = 4541 (30.611 sec)\n","INFO:tensorflow:global_step/sec: 0.032766\n","INFO:tensorflow:loss = 1.3151494, step = 4542 (30.520 sec)\n","INFO:tensorflow:global_step/sec: 0.0328575\n","INFO:tensorflow:loss = 1.6614916, step = 4543 (30.434 sec)\n","INFO:tensorflow:global_step/sec: 0.0328318\n","INFO:tensorflow:loss = 1.8087736, step = 4544 (30.459 sec)\n","INFO:tensorflow:global_step/sec: 0.0329437\n","INFO:tensorflow:loss = 1.3472824, step = 4545 (30.354 sec)\n","INFO:tensorflow:global_step/sec: 0.0329458\n","INFO:tensorflow:loss = 1.134157, step = 4546 (30.353 sec)\n","INFO:tensorflow:global_step/sec: 0.032922\n","INFO:tensorflow:loss = 1.1031686, step = 4547 (30.375 sec)\n","INFO:tensorflow:global_step/sec: 0.0330021\n","INFO:tensorflow:loss = 1.1596863, step = 4548 (30.300 sec)\n","INFO:tensorflow:global_step/sec: 0.0324932\n","INFO:tensorflow:loss = 1.3147522, step = 4549 (30.776 sec)\n","INFO:tensorflow:Saving checkpoints for 4550 into denseNet3d_result/model.ckpt.\n","INFO:tensorflow:global_step/sec: 0.0323433\n","INFO:tensorflow:loss = 1.4452988, step = 4550 (30.922 sec)\n","INFO:tensorflow:global_step/sec: 0.0328673\n","INFO:tensorflow:loss = 1.2175778, step = 4551 (30.422 sec)\n","INFO:tensorflow:global_step/sec: 0.0330531\n","INFO:tensorflow:loss = 1.0654693, step = 4552 (30.255 sec)\n","INFO:tensorflow:global_step/sec: 0.0324735\n","INFO:tensorflow:loss = 1.2954501, step = 4553 (30.794 sec)\n","INFO:tensorflow:global_step/sec: 0.0323919\n","INFO:tensorflow:loss = 1.631291, step = 4554 (30.872 sec)\n","INFO:tensorflow:global_step/sec: 0.0325698\n","INFO:tensorflow:loss = 1.1165416, step = 4555 (30.703 sec)\n","INFO:tensorflow:global_step/sec: 0.0322799\n","INFO:tensorflow:loss = 1.2403239, step = 4556 (30.979 sec)\n","INFO:tensorflow:global_step/sec: 0.0327549\n","INFO:tensorflow:loss = 1.167166, step = 4557 (30.530 sec)\n","INFO:tensorflow:global_step/sec: 0.0324118\n","INFO:tensorflow:loss = 1.0098776, step = 4558 (30.856 sec)\n","INFO:tensorflow:global_step/sec: 0.0324413\n","INFO:tensorflow:loss = 1.2603284, step = 4559 (30.825 sec)\n","INFO:tensorflow:global_step/sec: 0.0325432\n","INFO:tensorflow:loss = 0.93173665, step = 4560 (30.725 sec)\n","INFO:tensorflow:global_step/sec: 0.0318778\n","INFO:tensorflow:loss = 0.90880287, step = 4561 (31.370 sec)\n","INFO:tensorflow:global_step/sec: 0.0321548\n","INFO:tensorflow:loss = 1.2452469, step = 4562 (31.100 sec)\n","INFO:tensorflow:global_step/sec: 0.0321816\n","INFO:tensorflow:loss = 1.4763244, step = 4563 (31.073 sec)\n","INFO:tensorflow:global_step/sec: 0.032113\n","INFO:tensorflow:loss = 1.2140893, step = 4564 (31.140 sec)\n","INFO:tensorflow:global_step/sec: 0.0321393\n","INFO:tensorflow:loss = 0.9420525, step = 4565 (31.114 sec)\n","INFO:tensorflow:global_step/sec: 0.0322912\n","INFO:tensorflow:loss = 1.3951868, step = 4566 (30.971 sec)\n","INFO:tensorflow:global_step/sec: 0.0324662\n","INFO:tensorflow:loss = 1.1941762, step = 4567 (30.798 sec)\n","INFO:tensorflow:global_step/sec: 0.0326914\n","INFO:tensorflow:loss = 1.2173603, step = 4568 (30.589 sec)\n","INFO:tensorflow:global_step/sec: 0.032734\n","INFO:tensorflow:loss = 1.7708786, step = 4569 (30.552 sec)\n","INFO:tensorflow:Saving checkpoints for 4570 into denseNet3d_result/model.ckpt.\n","INFO:tensorflow:global_step/sec: 0.032679\n","INFO:tensorflow:loss = 1.4612125, step = 4570 (30.601 sec)\n","INFO:tensorflow:global_step/sec: 0.0328522\n","INFO:tensorflow:loss = 1.1258588, step = 4571 (30.436 sec)\n","INFO:tensorflow:global_step/sec: 0.0327138\n","INFO:tensorflow:loss = 1.483294, step = 4572 (30.568 sec)\n","INFO:tensorflow:global_step/sec: 0.0327461\n","INFO:tensorflow:loss = 1.2106882, step = 4573 (30.541 sec)\n","INFO:tensorflow:global_step/sec: 0.0329421\n","INFO:tensorflow:loss = 1.1377686, step = 4574 (30.353 sec)\n","INFO:tensorflow:global_step/sec: 0.032718\n","INFO:tensorflow:loss = 1.269486, step = 4575 (30.567 sec)\n","INFO:tensorflow:global_step/sec: 0.032779\n","INFO:tensorflow:loss = 1.3056315, step = 4576 (30.504 sec)\n","INFO:tensorflow:global_step/sec: 0.0326928\n","INFO:tensorflow:loss = 1.2681763, step = 4577 (30.587 sec)\n","INFO:tensorflow:global_step/sec: 0.0326052\n","INFO:tensorflow:loss = 1.6155674, step = 4578 (30.670 sec)\n","INFO:tensorflow:global_step/sec: 0.0328494\n","INFO:tensorflow:loss = 1.092233, step = 4579 (30.445 sec)\n","INFO:tensorflow:global_step/sec: 0.0327383\n","INFO:tensorflow:loss = 1.1746664, step = 4580 (30.542 sec)\n","INFO:tensorflow:global_step/sec: 0.0324192\n","INFO:tensorflow:loss = 1.2354581, step = 4581 (30.846 sec)\n","INFO:tensorflow:global_step/sec: 0.0323637\n","INFO:tensorflow:loss = 1.2912126, step = 4582 (30.899 sec)\n","INFO:tensorflow:global_step/sec: 0.0324847\n","INFO:tensorflow:loss = 1.3547261, step = 4583 (30.784 sec)\n","INFO:tensorflow:global_step/sec: 0.0326784\n","INFO:tensorflow:loss = 1.103268, step = 4584 (30.601 sec)\n","INFO:tensorflow:global_step/sec: 0.0323662\n","INFO:tensorflow:loss = 1.1127851, step = 4585 (30.896 sec)\n","INFO:tensorflow:global_step/sec: 0.0324686\n","INFO:tensorflow:loss = 1.3355196, step = 4586 (30.802 sec)\n","INFO:tensorflow:global_step/sec: 0.0328079\n","INFO:tensorflow:loss = 1.0923631, step = 4587 (30.477 sec)\n","INFO:tensorflow:global_step/sec: 0.0326339\n","INFO:tensorflow:loss = 1.3097285, step = 4588 (30.643 sec)\n","INFO:tensorflow:global_step/sec: 0.0328455\n","INFO:tensorflow:loss = 1.5974709, step = 4589 (30.445 sec)\n","INFO:tensorflow:Saving checkpoints for 4590 into denseNet3d_result/model.ckpt.\n","INFO:tensorflow:global_step/sec: 0.0323513\n","INFO:tensorflow:loss = 1.1462104, step = 4590 (30.911 sec)\n","INFO:tensorflow:global_step/sec: 0.032764\n","INFO:tensorflow:loss = 1.2253709, step = 4591 (30.524 sec)\n","INFO:tensorflow:global_step/sec: 0.0326447\n","INFO:tensorflow:loss = 0.91666687, step = 4592 (30.631 sec)\n","INFO:tensorflow:global_step/sec: 0.0325487\n","INFO:tensorflow:loss = 1.3985004, step = 4593 (30.723 sec)\n","INFO:tensorflow:global_step/sec: 0.0326488\n","INFO:tensorflow:loss = 1.0981351, step = 4594 (30.633 sec)\n","INFO:tensorflow:global_step/sec: 0.0326051\n","INFO:tensorflow:loss = 1.114178, step = 4595 (30.666 sec)\n","INFO:tensorflow:global_step/sec: 0.0327177\n","INFO:tensorflow:loss = 1.4981092, step = 4596 (30.566 sec)\n","INFO:tensorflow:global_step/sec: 0.0329161\n","INFO:tensorflow:loss = 1.2860256, step = 4597 (30.379 sec)\n","INFO:tensorflow:global_step/sec: 0.0328867\n","INFO:tensorflow:loss = 1.2933241, step = 4598 (30.407 sec)\n","INFO:tensorflow:global_step/sec: 0.0326883\n","INFO:tensorflow:loss = 1.3295586, step = 4599 (30.592 sec)\n","INFO:tensorflow:global_step/sec: 0.0326255\n","INFO:tensorflow:loss = 1.0887028, step = 4600 (30.651 sec)\n","INFO:tensorflow:global_step/sec: 0.0327636\n","INFO:tensorflow:loss = 1.1759571, step = 4601 (30.522 sec)\n","INFO:tensorflow:global_step/sec: 0.0327818\n","INFO:tensorflow:loss = 1.2564032, step = 4602 (30.505 sec)\n","INFO:tensorflow:global_step/sec: 0.0327508\n","INFO:tensorflow:loss = 0.90615034, step = 4603 (30.534 sec)\n","INFO:tensorflow:global_step/sec: 0.0323853\n","INFO:tensorflow:loss = 1.2458394, step = 4604 (30.878 sec)\n","INFO:tensorflow:global_step/sec: 0.0322709\n","INFO:tensorflow:loss = 1.1619323, step = 4605 (30.988 sec)\n","INFO:tensorflow:global_step/sec: 0.0324026\n","INFO:tensorflow:loss = 1.0075533, step = 4606 (30.862 sec)\n","INFO:tensorflow:global_step/sec: 0.0324594\n","INFO:tensorflow:loss = 1.1497924, step = 4607 (30.807 sec)\n","INFO:tensorflow:global_step/sec: 0.0323096\n","INFO:tensorflow:loss = 1.0984781, step = 4608 (30.951 sec)\n","INFO:tensorflow:global_step/sec: 0.0323507\n","INFO:tensorflow:loss = 1.3083951, step = 4609 (30.911 sec)\n","INFO:tensorflow:Saving checkpoints for 4610 into denseNet3d_result/model.ckpt.\n","INFO:tensorflow:global_step/sec: 0.0320857\n","INFO:tensorflow:loss = 1.2980027, step = 4610 (31.167 sec)\n","INFO:tensorflow:global_step/sec: 0.0321594\n","INFO:tensorflow:loss = 1.4100789, step = 4611 (31.095 sec)\n","INFO:tensorflow:global_step/sec: 0.032198\n","INFO:tensorflow:loss = 0.92693245, step = 4612 (31.058 sec)\n","INFO:tensorflow:global_step/sec: 0.0324273\n","INFO:tensorflow:loss = 1.2853694, step = 4613 (30.838 sec)\n","INFO:tensorflow:global_step/sec: 0.0324094\n","INFO:tensorflow:loss = 1.3106163, step = 4614 (30.856 sec)\n","INFO:tensorflow:global_step/sec: 0.0324239\n","INFO:tensorflow:loss = 1.5232819, step = 4615 (30.841 sec)\n","INFO:tensorflow:global_step/sec: 0.0325569\n","INFO:tensorflow:loss = 1.0477396, step = 4616 (30.716 sec)\n","INFO:tensorflow:global_step/sec: 0.0327576\n","INFO:tensorflow:loss = 1.2183781, step = 4617 (30.527 sec)\n","INFO:tensorflow:global_step/sec: 0.03262\n","INFO:tensorflow:loss = 1.0350771, step = 4618 (30.656 sec)\n","INFO:tensorflow:global_step/sec: 0.0329331\n","INFO:tensorflow:loss = 1.0211422, step = 4619 (30.365 sec)\n","INFO:tensorflow:global_step/sec: 0.0325019\n","INFO:tensorflow:loss = 1.1615632, step = 4620 (30.770 sec)\n","INFO:tensorflow:Saving checkpoints for 4620 into denseNet3d_result/model.ckpt.\n","INFO:tensorflow:Loss for final step: 1.1615632.\n","INFO:tensorflow:Calling model_fn.\n","Build 3D DenseNet-BC model with 3 blocks, 2 bottleneck layers and 2 composite layers each.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2019-07-16-16:27:42\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from denseNet3d_result/model.ckpt-4620\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Evaluation [4/45]\n","INFO:tensorflow:Evaluation [8/45]\n","INFO:tensorflow:Evaluation [12/45]\n","INFO:tensorflow:Evaluation [16/45]\n","INFO:tensorflow:Evaluation [20/45]\n","INFO:tensorflow:Evaluation [24/45]\n","INFO:tensorflow:Evaluation [28/45]\n","INFO:tensorflow:Evaluation [32/45]\n","INFO:tensorflow:Evaluation [36/45]\n","INFO:tensorflow:Evaluation [40/45]\n","INFO:tensorflow:Evaluation [44/45]\n","INFO:tensorflow:Evaluation [45/45]\n","INFO:tensorflow:Finished evaluation at 2019-07-16-16:36:11\n","INFO:tensorflow:Saving dict for global step 4620: eval_accuracy = 0.35444444, global_step = 4620, loss = 1.6496755\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4620: denseNet3d_result/model.ckpt-4620\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'eval_accuracy': 0.35444444, 'global_step': 4620, 'loss': 1.6496755}"]},"metadata":{"tags":[]},"execution_count":7}]}]}