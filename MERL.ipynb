{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ProgettoCV.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"TYUxb8Gvbq4y","colab_type":"code","outputId":"635d6f54-ff2b-4c71-f8a7-bcf24ee87260","executionInfo":{"status":"ok","timestamp":1563279972818,"user_tz":-120,"elapsed":18548,"user":{"displayName":"Manuel Verlengia","photoUrl":"","userId":"00922102153179523884"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6IRlOARiNIjT","colab_type":"code","outputId":"c6fb582b-6074-4cc4-e96b-2186952ba01f","executionInfo":{"status":"ok","timestamp":1563280011394,"user_tz":-120,"elapsed":28383,"user":{"displayName":"Manuel Verlengia","photoUrl":"","userId":"00922102153179523884"}},"colab":{"base_uri":"https://localhost:8080/","height":510}},"source":["!pip install tensorflow==1.12"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==1.12\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cc/ca70b78087015d21c5f3f93694107f34ebccb3be9624385a911d4b52ecef/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl (83.1MB)\n","\u001b[K     |████████████████████████████████| 83.1MB 1.3MB/s \n","\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.0.8)\n","Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (0.7.1)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (0.8.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (0.33.4)\n","Collecting tensorboard<1.13.0,>=1.12.0 (from tensorflow==1.12)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/53/8d32ce9471c18f8d99028b7cef2e5b39ea8765bd7ef250ca05b490880971/tensorboard-1.12.2-py3-none-any.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.1MB 37.3MB/s \n","\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.1.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.12.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.1.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.15.0)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (0.2.2)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.16.4)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (3.7.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.12) (2.8.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12) (3.1.1)\n","Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12) (0.15.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.12) (41.0.1)\n","Installing collected packages: tensorboard, tensorflow\n","  Found existing installation: tensorboard 1.14.0\n","    Uninstalling tensorboard-1.14.0:\n","      Successfully uninstalled tensorboard-1.14.0\n","  Found existing installation: tensorflow 1.14.0\n","    Uninstalling tensorflow-1.14.0:\n","      Successfully uninstalled tensorflow-1.14.0\n","Successfully installed tensorboard-1.12.2 tensorflow-1.12.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jnU7FCspQxVm","colab_type":"code","colab":{}},"source":["import os\n","from io import BytesIO\n","from PIL import Image\n","\n","import cv2\n","import tensorflow as tf\n","\n","def del_all_flags(FLAGS):\n","    flags_dict = FLAGS._flags()    \n","    keys_list = [keys for keys in flags_dict]    \n","    for keys in keys_list:\n","        FLAGS.__delattr__(keys)\n","\n","del_all_flags(tf.flags.FLAGS)\n","\n","\n","FLAGS = tf.app.flags\n","FLAGS.DEFINE_string('data_dir',\n","                    '/content/gdrive/My Drive/dataset',\n","                    'Path to the input data')\n","FLAGS.DEFINE_string('train_output_path',\n","                    'train.tfrecord',\n","                    'Path to output train TFRecord')\n","FLAGS.DEFINE_string('eval_output_path',\n","                    'eval.tfrecord',\n","                    'Path to output eval TFRecord')\n","FLAGS.DEFINE_float(\n","    'train_eval_split_factor', 0.75,\n","    'use this factor to split the train (default 3/4) and '\n","    'eval data (default 1/4) in data_dir')\n","FLAGS.DEFINE_integer('width', 120, 'customize image width')\n","FLAGS.DEFINE_integer('height', 100, 'customize image height')\n","FLAGS.DEFINE_integer('channel', 3, 'image color channel')\n","FLAGS.DEFINE_integer('skip_frames', 10,\n","                     'the number of frames we skip when we process the video')\n","FLAGS.DEFINE_integer('num_frames_per_clip', 16,\n","                     'the number of frames for a video clip')\n","FLAGS = FLAGS.FLAGS\n","\n","\n","\n","def get_clips(image_list):\n","    # Given a list of images, return video clips of (num_frames_per_clip) consecutive frames as a list.\n","    video_clips = []\n","    images_len = len(image_list)\n","    if images_len < FLAGS.num_frames_per_clip:\n","        return video_clips\n","\n","    # Prepare the first clip\n","    video_clips.append(image_list[:FLAGS.num_frames_per_clip])\n","\n","    num_of_extra_clip = int(\n","        (images_len - FLAGS.num_frames_per_clip) / FLAGS.skip_frames)\n","    for i in range(1, num_of_extra_clip + 1):\n","        start = i * FLAGS.skip_frames - 1\n","        end = start + FLAGS.num_frames_per_clip\n","        video_clips.append(image_list[start:end])\n","\n","    return video_clips\n","\n","def process_dataset(train_writer, eval_writer, data_dir):\n","    label = 0\n","    # [class1, class2, class3, ..., class n]\n","    for class_dir in os.listdir(data_dir):\n","        class_path = os.path.join(data_dir, class_dir)\n","        if os.path.isdir(class_path):\n","            # Set the label value for this class, start from 0\n","            label += 1\n","            print(\"Processing class: \" + str(label))\n","            # Process each video file in this class\n","            video_filenames = os.listdir(class_path)\n","            for video_filename in video_filenames[0:int(\n","                    FLAGS.train_eval_split_factor * len(video_filenames))]:\n","                process_video(train_writer, class_path, video_filename, label)\n","            for video_filename in video_filenames[\n","                    int(FLAGS.train_eval_split_factor *\n","                        len(video_filenames)):len(video_filenames)]:\n","                process_video(eval_writer, class_path, video_filename, label)\n","\n","\n","def process_video(writer, class_path, video_filename, label):\n","    video_filename_path = os.path.join(class_path, video_filename)\n","    if video_filename_path.endswith('mp4'):\n","        video_clips = _convert_video_to_clips(video_filename_path)\n","        # Convert the clip to tf record\n","        for clip in video_clips:\n","            tf_example = create_tf_example(raw=clip, label=label)\n","            writer.write(tf_example.SerializeToString())\n","\n","\n","def _convert_video_to_clips(video_path):\n","    # Use opencv to read video to list of images\n","    video_images_list = []\n","    cap = cv2.VideoCapture(video_path)\n","    while cap.isOpened():\n","        # frame shape [height, width, channel]\n","        _, frame = cap.read()\n","        try:\n","            # pil_image shape [width, height, channel]\n","            pil_image = Image.fromarray(frame)\n","            # Resize the image and convert the image according to the channel information\n","            if FLAGS.channel == 1:\n","                pil_image = pil_image.resize((FLAGS.width, FLAGS.height),\n","                                             Image.NEAREST).convert('L')\n","            else:\n","                pil_image = pil_image.resize((FLAGS.width, FLAGS.height),\n","                                             Image.NEAREST)\n","            # Encode the image to JPEG\n","            with BytesIO() as buffer:\n","                pil_image.save(buffer, format=\"JPEG\")\n","                video_images_list.append(buffer.getvalue())\n","        except AttributeError:\n","            # Fail to read the image\n","            break\n","\n","    # Convert list of images to clips of images with type np.float32\n","    return get_clips(image_list=video_images_list)\n","\n","\n","def _bytelist_feature(value):\n","    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n","\n","\n","def _bytes_feature(value):\n","    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n","\n","\n","def _int64_feature(value):\n","    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n","\n","\n","def create_tf_example(raw, label):\n","    return tf.train.Example(\n","        features=tf.train.Features(\n","            feature={\n","                'clip/width': _int64_feature(FLAGS.width),\n","                'clip/height': _int64_feature(FLAGS.height),\n","                'clip/channel': _int64_feature(FLAGS.channel),\n","                'clip/raw': _bytelist_feature(raw),\n","                'clip/label': _int64_feature(label)\n","            }))\n","\n","\n","def get_total_video_clip_number(data_path):\n","    count = 0\n","    for _ in tf.python_io.tf_record_iterator(data_path):\n","        count += 1\n","    return count\n","\n","\n","def main(_):\n","    # Write the dataset\n","    train_writer = tf.python_io.TFRecordWriter(FLAGS.train_output_path)\n","    eval_writer = tf.python_io.TFRecordWriter(FLAGS.eval_output_path)\n","\n","    process_dataset(\n","        train_writer=train_writer,\n","        eval_writer=eval_writer,\n","        data_dir=FLAGS.data_dir)\n","\n","    train_writer.close()\n","    eval_writer.close()\n","\n","    # Count the dataset record\n","    print(\"Total clips in train dataset: \" +\n","          str(get_total_video_clip_number(FLAGS.train_output_path)))\n","    print(\"Total clips in eval dataset: \" +\n","          str(get_total_video_clip_number(FLAGS.eval_output_path)))\n","\n","\n","#if __name__ == '__main__':\n","#    tf.app.run()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"5107b361-bce6-41b1-a541-bfaaa96320ac","id":"eq5nVkvCJhG4","executionInfo":{"status":"ok","timestamp":1563318217032,"user_tz":-120,"elapsed":3459207,"user":{"displayName":"Manuel Verlengia","photoUrl":"","userId":"00922102153179523884"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["class DenseNet3D(object):\n","    \"\"\"3D DenseNet Model class\"\"\"\n","\n","    def __init__(\n","            self,\n","            video_clips,  # Shape: [batch_size, sequence_length, height, width, channels]\n","            labels,  # Shape: [batch_size, num_classes] \n","            initial_learning_rate,\n","            decay_step,\n","            lr_decay_factor,\n","            num_classes,\n","            growth_rate,\n","            network_depth,\n","            total_blocks,\n","            keep_prob,\n","            weight_decay,\n","            reduction,\n","            bc_mode=False,\n","            **kwargs):\n","        self.video_clips = video_clips\n","        self.labels = labels\n","        self.num_classes = num_classes\n","        self.growth_rate = growth_rate\n","        self.network_depth = network_depth\n","\n","        # How many features will be received after first convolution value\n","        self.first_output_features = growth_rate * 2\n","\n","        self.total_blocks = total_blocks\n","        self.layers_per_block = (network_depth -\n","                                 (total_blocks + 1)) // total_blocks\n","\n","        # Compression rate at the transition layers\n","        self.reduction = reduction\n","        self.bc_mode = bc_mode\n","        if not bc_mode:\n","            self.reduction = 1.0\n","            print(\n","                \"Build 3D DenseNet model with %d blocks, %d composite layers each.\"\n","                % (total_blocks, self.layers_per_block))\n","\n","        if bc_mode:\n","            self.layers_per_block = self.layers_per_block // 2\n","            print(\n","                \"Build 3D DenseNet-BC model with %d blocks, %d bottleneck layers and %d composite layers each.\"\n","                % (total_blocks, self.layers_per_block, self.layers_per_block))\n","\n","        self.keep_prob = keep_prob\n","        self.weight_decay = weight_decay\n","        self._is_training = tf.convert_to_tensor(True)\n","\n","        # Initialize the global step\n","        self.global_step = tf.train.get_or_create_global_step()\n","\n","        self.learning_rate = tf.train.exponential_decay(\n","            initial_learning_rate,\n","            self.global_step,\n","            decay_step,\n","            lr_decay_factor,\n","            staircase=True)\n","\n","        self._build_graph()\n","\n","    def _build_graph(self):\n","        # First convolution layer\n","        with tf.variable_scope('Initial_convolution'):\n","            output = self._conv3d(\n","                self.video_clips,\n","                out_features_count=self.first_output_features,\n","                kernel_size=7,\n","                strides=[1, 1, 2, 2, 1])\n","            output = self._pool(output, k=3, d=2, k_stride=2, d_stride=1)\n","\n","        # Add 3D DenseNet blocks\n","        for block in range(self.total_blocks):\n","            with tf.variable_scope(\"Block_%d\" % block):\n","                output = self._add_block(output, self.growth_rate,\n","                                         self.layers_per_block)\n","            # The last block exist without transition layer\n","            if block != self.total_blocks - 1:\n","                with tf.variable_scope(\"Transition_after_block_%d\" % block):\n","                    output = self._transition_layer(output, pool_depth=2)\n","\n","        # Fully connected layers\n","        with tf.variable_scope('Transition_to_classes'):\n","            self._logits = self._trainsition_layer_to_classes(output)\n","\n","        # Prediction result\n","        self._prediction = tf.argmax(self._logits, 1)\n","\n","        # Losses\n","        self._cross_entropy = tf.reduce_mean(\n","            tf.nn.sparse_softmax_cross_entropy_with_logits(\n","                logits=self._logits, labels=self.labels),\n","            name='Cross_entropy')\n","        self.l2_loss = tf.add_n(\n","            [tf.nn.l2_loss(var) for var in tf.trainable_variables()])\n","        self.total_loss = self._cross_entropy + self.l2_loss * self.weight_decay\n","\n","        # Optimizer and training op\n","        self._train_op = tf.contrib.layers.optimize_loss(\n","            loss=self.total_loss,\n","            global_step=self.global_step,\n","            learning_rate=self.learning_rate,\n","            optimizer='Momentum')\n","\n","    @property\n","    def logits(self):\n","        return self._logits\n","\n","    @property\n","    def train_op(self):\n","        return self._train_op\n","\n","    @property\n","    def losses(self):\n","        return self._cross_entropy\n","\n","    @property\n","    def prediction(self):\n","        return self._prediction\n","\n","    @property\n","    def accuracy(self):\n","        correct_prediction = tf.equal(tf.argmax(self._logits, 1), self.labels)\n","        return tf.metrics.mean(tf.cast(correct_prediction, tf.float32))\n","\n","    @property\n","    def is_training(self):\n","        return self._is_training\n","\n","    @is_training.setter\n","    def is_training(self, value):\n","        self._is_training = tf.convert_to_tensor(value)\n","\n","    def _conv3d(self,\n","                inputs,\n","                out_features_count,\n","                kernel_size,\n","                strides=[1, 1, 1, 1, 1],\n","                padding='SAME'):\n","        input_features_count = int(inputs.get_shape()[-1])\n","        kernel = tf.get_variable(\n","            'kernel',\n","            shape=[\n","                kernel_size, kernel_size, kernel_size, input_features_count,\n","                out_features_count\n","            ],\n","            initializer=tf.random_normal_initializer())\n","        with tf.name_scope('3d_conv'):\n","            return tf.nn.conv3d(\n","                inputs, filter=kernel, strides=strides, padding=padding)\n","\n","    def _pool(self,\n","              inputs,\n","              k,\n","              d=2,\n","              k_stride=None,\n","              d_stride=None,\n","              width_k=None,\n","              k_stride_width=None):\n","        if not width_k:\n","            width_k = k\n","        kernel_size = [1, d, k, width_k, 1]\n","        if not k_stride:\n","            k_stride = k\n","        if not k_stride_width:\n","            k_stride_width = k_stride\n","        if not d_stride:\n","            d_stride = d\n","        strides = [1, d_stride, k_stride, k_stride_width, 1]\n","        return tf.nn.max_pool3d(\n","            inputs, ksize=kernel_size, strides=strides, padding='SAME')\n","\n","    def _add_block(self, inputs, growth_rate, layers_per_block):\n","        for layer in range(layers_per_block):\n","            with tf.variable_scope(\"layer_%d\" % layer):\n","                return self._add_internal_layer(inputs, growth_rate)\n","\n","    def _add_internal_layer(self, inputs, growth_rate):\n","        if not self.bc_mode:\n","            composite_out = self._composite_function(\n","                inputs, out_features_count=growth_rate, kernel_size=3)\n","        elif self.bc_mode:\n","            bottleneck_out = self._bottleneck(\n","                inputs, out_features_count=growth_rate)\n","            composite_out = self._composite_function(\n","                bottleneck_out, out_features_count=growth_rate, kernel_size=3)\n","\n","        with tf.name_scope('concat'):\n","            return tf.concat(axis=4, values=(inputs, composite_out))\n","\n","    def _composite_function(self, inputs, out_features_count, kernel_size):\n","        with tf.variable_scope('composite_function'):\n","            # Batch normalization\n","            output = self._batch_norm(inputs)\n","            # ReLU\n","            with tf.name_scope('ReLU'):\n","                output = tf.nn.relu(output)\n","            # Convolution\n","            output = self._conv3d(\n","                output,\n","                out_features_count=out_features_count,\n","                kernel_size=kernel_size)\n","            # Dropout\n","            output = self._dropout(output)\n","        return output\n","\n","    def _bottleneck(self, inputs, out_features_count):\n","        with tf.variable_scope('bottleneck'):\n","            # Batch normalization\n","            output = self._batch_norm(inputs)\n","            # ReLU\n","            with tf.name_scope('ReLU'):\n","                output = tf.nn.relu(output)\n","\n","            inter_features = out_features_count * 4\n","            output = self._conv3d(\n","                output,\n","                out_features_count=inter_features,\n","                kernel_size=1,\n","                padding='VALID')\n","            output = self._dropout(output)\n","        return output\n","\n","    def _batch_norm(self, inputs):\n","        with tf.name_scope('batch_normalization'):\n","            output = tf.contrib.layers.batch_norm(\n","                inputs,\n","                scale=True,\n","                is_training=self._is_training,\n","                updates_collections=None)\n","        return output\n","\n","    def _dropout(self, inputs):\n","        if self.keep_prob < 1:\n","            with tf.name_scope('dropout'):\n","                output = tf.cond(self._is_training,\n","                                 lambda: tf.nn.dropout(inputs, self.keep_prob),\n","                                 lambda: inputs)\n","        else:\n","            output = inputs\n","        return output\n","\n","    def _transition_layer(self, inputs, pool_depth):\n","        out_features_count = int(int(inputs.get_shape()[-1]) * self.reduction)\n","        output = self._composite_function(\n","            inputs, out_features_count=out_features_count, kernel_size=1)\n","        with tf.name_scope('pooling'):\n","            output = self._pool(output, k=2, d=pool_depth)\n","        return output\n","\n","    def _trainsition_layer_to_classes(self, inputs):\n","        # Batch normalization\n","        output = self._batch_norm(inputs)\n","        # ReLU\n","        with tf.name_scope('ReLU'):\n","            output = tf.nn.relu(output)\n","        # pooling\n","        last_pool_kernel_width = int(output.get_shape()[-2])\n","        last_pool_kernel_height = int(output.get_shape()[-3])\n","        last_sequence_length = int(output.get_shape()[1])\n","        with tf.name_scope('pooling'):\n","            output = self._pool(\n","                output,\n","                k=last_pool_kernel_height,\n","                d=last_sequence_length,\n","                width_k=last_pool_kernel_width,\n","                k_stride_width=last_pool_kernel_width)\n","        # Fully connected\n","        features_total = int(output.get_shape()[-1])\n","        output = tf.reshape(output, [-1, features_total])\n","        weight = tf.get_variable(\n","            'fc_w',\n","            shape=[features_total, self.num_classes],\n","            initializer=tf.contrib.layers.xavier_initializer())\n","        bias = tf.get_variable(\n","            'fc_bias',\n","            shape=[self.num_classes],\n","            initializer=tf.zeros_initializer())\n","        logits = tf.matmul(output, weight) + bias\n","        return logits\n","\n","def model_fn(features, labels, mode, params):\n","    # Define the model\n","    model = DenseNet3D(\n","        video_clips=features['video_clips'], labels=labels, **params)\n","\n","    # Get the prediction result\n","    if mode == tf.estimator.ModeKeys.PREDICT:\n","        model.is_training = False\n","        return _predict_result(model.logits)\n","\n","    return tf.estimator.EstimatorSpec(\n","        mode=mode,\n","        loss=model.losses,\n","        train_op=model.train_op,\n","        eval_metric_ops={'eval_accuracy': model.accuracy})\n","\n","\n","def _predict_result(model):\n","    predictions = {'probabilities': model.prediction, 'logits': model.logits}\n","    return tf.estimator.EstimatorSpec(\n","        mode=tf.estimator.ModeKeys.PREDICT, predictions=predictions)\n","\n","\n","def serving_input_fn(params):\n","    inputs = {\n","        'video_clips':\n","        tf.placeholder(\n","            tf.float32,\n","            shape=[\n","                None, params['num_frames_per_clip'], params['height'],\n","                params['width'], params['channel']\n","            ])\n","    }\n","    return tf.estimator.export.build_raw_serving_input_receiver_fn(inputs)()\n","\n","\n","def train_input_fn(training_dir, params):\n","    directory = os.path.join(training_dir, 'train.tfrecord')\n","    return _build_tfrecord_dataset(directory, params['train_total_video_clip'],\n","                                   **params)\n","\n","\n","def eval_input_fn(evaluating_dir, params):\n","    directory = os.path.join(evaluating_dir, 'eval.tfrecord')\n","    return _build_tfrecord_dataset(directory, params['eval_total_video_clip'],\n","                                   **params)\n","\n","\n","def _build_tfrecord_dataset(directory, total_clip_num, batch_size, **params):\n","    '''\n","    Buffer the training dataset to TFRecordDataset with the following video shape\n","    [num_frames_per_clip, height, width, channel]\n","    ex: [16, 100, 120, 3]\n","    '''\n","    dataset = tf.data.TFRecordDataset(directory)\n","    dataset = dataset.shuffle(buffer_size=total_clip_num)\n","    dataset = dataset.map(\n","        map_func=\n","        lambda serialized_example: _parser(serialized_example, **params))\n","    dataset = dataset.repeat()\n","    iterator = dataset.batch(batch_size=batch_size).make_one_shot_iterator()\n","    clips, labels = iterator.get_next()\n","    return {'video_clips': clips}, labels\n","\n","\n","def _parser(serialized_example, num_frames_per_clip, **params):\n","    features = tf.parse_single_example(\n","        serialized_example,\n","        features={\n","            'clip/width': tf.FixedLenFeature([], tf.int64),\n","            'clip/height': tf.FixedLenFeature([], tf.int64),\n","            'clip/channel': tf.FixedLenFeature([], tf.int64),\n","            'clip/raw': tf.FixedLenFeature([num_frames_per_clip], tf.string),\n","            'clip/label': tf.FixedLenFeature([], tf.int64)\n","        })\n","\n","    def mapping_func(image):\n","        return _decode_image(image, **params)\n","\n","    clip = tf.map_fn(mapping_func, features['clip/raw'], dtype=tf.float32)\n","    return clip, features['clip/label']\n","\n","\n","def _decode_image(image, channel, width, height, **params):\n","    image = tf.image.decode_jpeg(image, channels=channel)\n","    # This set_shape step is necesary for the last trainsition_layer_to_classes layer in the model\n","    image.set_shape([height, width, channel])\n","    image = tf.cast(image, tf.float32)\n","    return image\n","\n","\"\"\"This is the main class\"\"\"\n","\n","\n","MODEL_DIR = 'denseNet3d_result'\n","DATA_DIR = '/content/gdrive/My Drive/DatasetMERL'\n","\n","HYPERPARAMETERS = {\n","    'num_classes': 6,  # The number of the classes that this dataset had\n","    'batch_size': 20,\n","    'initial_learning_rate': 0.1,\n","    'decay_step': 5000,\n","    'lr_decay_factor':\n","    0.1,  # Learning rate will decay by a factor for every decay_step\n","    'growth_rate': 12,  # Grows rate for every layer [12, 24, 40]\n","    'network_depth': 20,  # Depth of the whole network [20, 40, 250]\n","    'total_blocks': 3,  # Total blocks of layers stack\n","    'keep_prob': 0.9,  # Keep probability for dropout\n","    'weight_decay': 1e-4,  # Weight decay for L2 loss\n","    'model_type': 'DenseNet3D',\n","    'reduction': 0.5,  # Reduction rate at transition layer for the models\n","    'bc_mode': True,\n","    'num_frames_per_clip': 16,  # The length of the video clip\n","    'width': 120,\n","    'height': 100,\n","    'channel': 3,\n","    'train_total_video_clip': 21827,\n","    'eval_total_video_clip': 5862\n","}\n","\n","TFRUNCONFIG = tf.estimator.RunConfig(\n","    log_step_count_steps=1, save_summary_steps=1, model_dir=MODEL_DIR)\n","\n","CLASSIFIER = tf.estimator.Estimator(\n","    model_fn=model_fn, params=HYPERPARAMETERS, config=TFRUNCONFIG)\n","\n","CLASSIFIER.train(\n","    input_fn=lambda: train_input_fn(DATA_DIR, HYPERPARAMETERS),\n","    steps=250)\n","\n","CLASSIFIER.evaluate(\n","    input_fn=lambda: eval_input_fn(DATA_DIR, HYPERPARAMETERS),\n","    steps=100)\n","\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Using config: {'_model_dir': 'denseNet3d_result', '_tf_random_seed': None, '_save_summary_steps': 1, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2f7fcbe5c0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","INFO:tensorflow:Calling model_fn.\n","Build 3D DenseNet-BC model with 3 blocks, 2 bottleneck layers and 2 composite layers each.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from denseNet3d_result/model.ckpt-9810\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Saving checkpoints for 9810 into denseNet3d_result/model.ckpt.\n","INFO:tensorflow:loss = 1.3992285, step = 9811\n","INFO:tensorflow:global_step/sec: 0.0352222\n","INFO:tensorflow:loss = 1.5572636, step = 9812 (28.397 sec)\n","INFO:tensorflow:global_step/sec: 0.0351167\n","INFO:tensorflow:loss = 1.6739935, step = 9813 (28.472 sec)\n","INFO:tensorflow:global_step/sec: 0.0361925\n","INFO:tensorflow:loss = 1.6248999, step = 9814 (27.630 sec)\n","INFO:tensorflow:global_step/sec: 0.0364683\n","INFO:tensorflow:loss = 1.7336346, step = 9815 (27.421 sec)\n","INFO:tensorflow:global_step/sec: 0.0349249\n","INFO:tensorflow:loss = 1.5008886, step = 9816 (28.633 sec)\n","INFO:tensorflow:global_step/sec: 0.0354905\n","INFO:tensorflow:loss = 1.5008414, step = 9817 (28.177 sec)\n","INFO:tensorflow:global_step/sec: 0.0356454\n","INFO:tensorflow:loss = 1.5329138, step = 9818 (28.054 sec)\n","INFO:tensorflow:global_step/sec: 0.034937\n","INFO:tensorflow:loss = 1.4954958, step = 9819 (28.623 sec)\n","INFO:tensorflow:global_step/sec: 0.0357149\n","INFO:tensorflow:loss = 1.5177306, step = 9820 (28.000 sec)\n","INFO:tensorflow:global_step/sec: 0.034313\n","INFO:tensorflow:loss = 1.4933126, step = 9821 (29.144 sec)\n","INFO:tensorflow:global_step/sec: 0.0347872\n","INFO:tensorflow:loss = 1.469271, step = 9822 (28.746 sec)\n","INFO:tensorflow:global_step/sec: 0.035455\n","INFO:tensorflow:loss = 1.5749133, step = 9823 (28.205 sec)\n","INFO:tensorflow:global_step/sec: 0.0348068\n","INFO:tensorflow:loss = 1.4824641, step = 9824 (28.731 sec)\n","INFO:tensorflow:global_step/sec: 0.0364084\n","INFO:tensorflow:loss = 1.4138771, step = 9825 (27.466 sec)\n","INFO:tensorflow:global_step/sec: 0.0354491\n","INFO:tensorflow:loss = 1.6146059, step = 9826 (28.210 sec)\n","INFO:tensorflow:global_step/sec: 0.0348371\n","INFO:tensorflow:loss = 1.4814463, step = 9827 (28.704 sec)\n","INFO:tensorflow:global_step/sec: 0.0364723\n","INFO:tensorflow:loss = 1.5996381, step = 9828 (27.418 sec)\n","INFO:tensorflow:global_step/sec: 0.0356968\n","INFO:tensorflow:loss = 1.3869021, step = 9829 (28.015 sec)\n","INFO:tensorflow:global_step/sec: 0.0356102\n","INFO:tensorflow:loss = 1.5674103, step = 9830 (28.082 sec)\n","INFO:tensorflow:global_step/sec: 0.0358443\n","INFO:tensorflow:loss = 1.538331, step = 9831 (27.900 sec)\n","INFO:tensorflow:Saving checkpoints for 9832 into denseNet3d_result/model.ckpt.\n","INFO:tensorflow:global_step/sec: 0.0348972\n","INFO:tensorflow:loss = 1.4817321, step = 9832 (28.652 sec)\n","INFO:tensorflow:global_step/sec: 0.0362817\n","INFO:tensorflow:loss = 1.4292948, step = 9833 (27.562 sec)\n","INFO:tensorflow:global_step/sec: 0.0363535\n","INFO:tensorflow:loss = 1.4710704, step = 9834 (27.508 sec)\n","INFO:tensorflow:global_step/sec: 0.0360639\n","INFO:tensorflow:loss = 1.6396713, step = 9835 (27.729 sec)\n","INFO:tensorflow:global_step/sec: 0.0361521\n","INFO:tensorflow:loss = 1.7254121, step = 9836 (27.662 sec)\n","INFO:tensorflow:global_step/sec: 0.0362171\n","INFO:tensorflow:loss = 1.4675913, step = 9837 (27.611 sec)\n","INFO:tensorflow:global_step/sec: 0.0359366\n","INFO:tensorflow:loss = 1.5222514, step = 9838 (27.826 sec)\n","INFO:tensorflow:global_step/sec: 0.0363522\n","INFO:tensorflow:loss = 1.5669508, step = 9839 (27.508 sec)\n","INFO:tensorflow:global_step/sec: 0.0363307\n","INFO:tensorflow:loss = 1.328629, step = 9840 (27.525 sec)\n","INFO:tensorflow:global_step/sec: 0.0356151\n","INFO:tensorflow:loss = 1.391989, step = 9841 (28.078 sec)\n","INFO:tensorflow:global_step/sec: 0.0361434\n","INFO:tensorflow:loss = 1.615392, step = 9842 (27.670 sec)\n","INFO:tensorflow:global_step/sec: 0.035925\n","INFO:tensorflow:loss = 1.6510181, step = 9843 (27.837 sec)\n","INFO:tensorflow:global_step/sec: 0.0357012\n","INFO:tensorflow:loss = 1.5186218, step = 9844 (28.006 sec)\n","INFO:tensorflow:global_step/sec: 0.0357231\n","INFO:tensorflow:loss = 1.7194284, step = 9845 (27.993 sec)\n","INFO:tensorflow:global_step/sec: 0.0355947\n","INFO:tensorflow:loss = 1.2988117, step = 9846 (28.095 sec)\n","INFO:tensorflow:global_step/sec: 0.0359752\n","INFO:tensorflow:loss = 1.5112101, step = 9847 (27.796 sec)\n","INFO:tensorflow:global_step/sec: 0.0366126\n","INFO:tensorflow:loss = 1.5258625, step = 9848 (27.313 sec)\n","INFO:tensorflow:global_step/sec: 0.0363452\n","INFO:tensorflow:loss = 1.7113745, step = 9849 (27.514 sec)\n","INFO:tensorflow:global_step/sec: 0.0361011\n","INFO:tensorflow:loss = 1.3678364, step = 9850 (27.703 sec)\n","INFO:tensorflow:global_step/sec: 0.0358689\n","INFO:tensorflow:loss = 1.7225395, step = 9851 (27.876 sec)\n","INFO:tensorflow:global_step/sec: 0.0362984\n","INFO:tensorflow:loss = 1.4361188, step = 9852 (27.552 sec)\n","INFO:tensorflow:global_step/sec: 0.0362999\n","INFO:tensorflow:loss = 1.4905264, step = 9853 (27.546 sec)\n","INFO:tensorflow:Saving checkpoints for 9854 into denseNet3d_result/model.ckpt.\n","INFO:tensorflow:global_step/sec: 0.0354919\n","INFO:tensorflow:loss = 1.5034883, step = 9854 (28.175 sec)\n","INFO:tensorflow:global_step/sec: 0.0348872\n","INFO:tensorflow:loss = 1.4174502, step = 9855 (28.664 sec)\n","INFO:tensorflow:global_step/sec: 0.0345401\n","INFO:tensorflow:loss = 1.6541679, step = 9856 (28.952 sec)\n","INFO:tensorflow:global_step/sec: 0.035293\n","INFO:tensorflow:loss = 1.6273588, step = 9857 (28.335 sec)\n","INFO:tensorflow:global_step/sec: 0.0359027\n","INFO:tensorflow:loss = 1.5605062, step = 9858 (27.852 sec)\n","INFO:tensorflow:global_step/sec: 0.0351126\n","INFO:tensorflow:loss = 1.490998, step = 9859 (28.480 sec)\n","INFO:tensorflow:global_step/sec: 0.0350398\n","INFO:tensorflow:loss = 1.6221968, step = 9860 (28.539 sec)\n","INFO:tensorflow:global_step/sec: 0.034616\n","INFO:tensorflow:loss = 1.5646064, step = 9861 (28.892 sec)\n","INFO:tensorflow:global_step/sec: 0.0343681\n","INFO:tensorflow:loss = 1.5008183, step = 9862 (29.093 sec)\n","INFO:tensorflow:global_step/sec: 0.0352086\n","INFO:tensorflow:loss = 1.5455487, step = 9863 (28.405 sec)\n","INFO:tensorflow:global_step/sec: 0.0345365\n","INFO:tensorflow:loss = 1.5685117, step = 9864 (28.952 sec)\n","INFO:tensorflow:global_step/sec: 0.0348135\n","INFO:tensorflow:loss = 1.6281452, step = 9865 (28.725 sec)\n","INFO:tensorflow:global_step/sec: 0.0340252\n","INFO:tensorflow:loss = 1.5594518, step = 9866 (29.393 sec)\n","INFO:tensorflow:global_step/sec: 0.0354557\n","INFO:tensorflow:loss = 1.417443, step = 9867 (28.201 sec)\n","INFO:tensorflow:global_step/sec: 0.0359006\n","INFO:tensorflow:loss = 1.6385857, step = 9868 (27.855 sec)\n","INFO:tensorflow:global_step/sec: 0.0358867\n","INFO:tensorflow:loss = 1.4181432, step = 9869 (27.866 sec)\n","INFO:tensorflow:global_step/sec: 0.0356651\n","INFO:tensorflow:loss = 1.4094751, step = 9870 (28.038 sec)\n","INFO:tensorflow:global_step/sec: 0.0348975\n","INFO:tensorflow:loss = 1.5737959, step = 9871 (28.655 sec)\n","INFO:tensorflow:global_step/sec: 0.0343765\n","INFO:tensorflow:loss = 1.5555494, step = 9872 (29.091 sec)\n","INFO:tensorflow:global_step/sec: 0.0344801\n","INFO:tensorflow:loss = 1.5039554, step = 9873 (29.005 sec)\n","INFO:tensorflow:global_step/sec: 0.0350944\n","INFO:tensorflow:loss = 1.4894106, step = 9874 (28.491 sec)\n","INFO:tensorflow:Saving checkpoints for 9875 into denseNet3d_result/model.ckpt.\n","INFO:tensorflow:global_step/sec: 0.0338161\n","INFO:tensorflow:loss = 1.4963245, step = 9875 (29.571 sec)\n","INFO:tensorflow:global_step/sec: 0.034927\n","INFO:tensorflow:loss = 1.62241, step = 9876 (28.631 sec)\n","INFO:tensorflow:global_step/sec: 0.0357921\n","INFO:tensorflow:loss = 1.5148028, step = 9877 (27.943 sec)\n","INFO:tensorflow:global_step/sec: 0.0352496\n","INFO:tensorflow:loss = 1.6803726, step = 9878 (28.369 sec)\n","INFO:tensorflow:global_step/sec: 0.0353705\n","INFO:tensorflow:loss = 1.5554953, step = 9879 (28.270 sec)\n","INFO:tensorflow:global_step/sec: 0.0345009\n","INFO:tensorflow:loss = 1.4478452, step = 9880 (28.983 sec)\n","INFO:tensorflow:global_step/sec: 0.0356041\n","INFO:tensorflow:loss = 1.4575917, step = 9881 (28.087 sec)\n","INFO:tensorflow:global_step/sec: 0.0348117\n","INFO:tensorflow:loss = 1.5353456, step = 9882 (28.726 sec)\n","INFO:tensorflow:global_step/sec: 0.0349052\n","INFO:tensorflow:loss = 1.5541595, step = 9883 (28.649 sec)\n","INFO:tensorflow:global_step/sec: 0.0346602\n","INFO:tensorflow:loss = 1.6121414, step = 9884 (28.856 sec)\n","INFO:tensorflow:global_step/sec: 0.0341799\n","INFO:tensorflow:loss = 1.6026256, step = 9885 (29.254 sec)\n","INFO:tensorflow:global_step/sec: 0.0345418\n","INFO:tensorflow:loss = 1.5062282, step = 9886 (28.949 sec)\n","INFO:tensorflow:global_step/sec: 0.0354356\n","INFO:tensorflow:loss = 1.4966033, step = 9887 (28.224 sec)\n","INFO:tensorflow:global_step/sec: 0.0358502\n","INFO:tensorflow:loss = 1.411226, step = 9888 (27.891 sec)\n","INFO:tensorflow:global_step/sec: 0.0347778\n","INFO:tensorflow:loss = 1.5909607, step = 9889 (28.753 sec)\n","INFO:tensorflow:global_step/sec: 0.0346981\n","INFO:tensorflow:loss = 1.6314952, step = 9890 (28.820 sec)\n","INFO:tensorflow:global_step/sec: 0.0347974\n","INFO:tensorflow:loss = 1.4474747, step = 9891 (28.738 sec)\n","INFO:tensorflow:global_step/sec: 0.0348276\n","INFO:tensorflow:loss = 1.5751128, step = 9892 (28.714 sec)\n","INFO:tensorflow:global_step/sec: 0.0348136\n","INFO:tensorflow:loss = 1.6112297, step = 9893 (28.727 sec)\n","INFO:tensorflow:global_step/sec: 0.0342319\n","INFO:tensorflow:loss = 1.508798, step = 9894 (29.211 sec)\n","INFO:tensorflow:global_step/sec: 0.034339\n","INFO:tensorflow:loss = 1.3932914, step = 9895 (29.118 sec)\n","INFO:tensorflow:Saving checkpoints for 9896 into denseNet3d_result/model.ckpt.\n","INFO:tensorflow:global_step/sec: 0.0342622\n","INFO:tensorflow:loss = 1.5078958, step = 9896 (29.186 sec)\n","INFO:tensorflow:global_step/sec: 0.035447\n","INFO:tensorflow:loss = 1.6273155, step = 9897 (28.212 sec)\n","INFO:tensorflow:global_step/sec: 0.0352308\n","INFO:tensorflow:loss = 1.4306844, step = 9898 (28.384 sec)\n","INFO:tensorflow:global_step/sec: 0.035427\n","INFO:tensorflow:loss = 1.470785, step = 9899 (28.232 sec)\n","INFO:tensorflow:global_step/sec: 0.0353163\n","INFO:tensorflow:loss = 1.6274618, step = 9900 (28.310 sec)\n","INFO:tensorflow:global_step/sec: 0.0350803\n","INFO:tensorflow:loss = 1.5164512, step = 9901 (28.506 sec)\n","INFO:tensorflow:global_step/sec: 0.0350832\n","INFO:tensorflow:loss = 1.5281569, step = 9902 (28.504 sec)\n","INFO:tensorflow:global_step/sec: 0.0346102\n","INFO:tensorflow:loss = 1.5145438, step = 9903 (28.893 sec)\n","INFO:tensorflow:global_step/sec: 0.0346617\n","INFO:tensorflow:loss = 1.5633523, step = 9904 (28.854 sec)\n","INFO:tensorflow:global_step/sec: 0.0350651\n","INFO:tensorflow:loss = 1.4125961, step = 9905 (28.515 sec)\n","INFO:tensorflow:global_step/sec: 0.0346668\n","INFO:tensorflow:loss = 1.5647602, step = 9906 (28.847 sec)\n","INFO:tensorflow:global_step/sec: 0.0346159\n","INFO:tensorflow:loss = 1.4302026, step = 9907 (28.887 sec)\n","INFO:tensorflow:global_step/sec: 0.0350635\n","INFO:tensorflow:loss = 1.5724823, step = 9908 (28.524 sec)\n","INFO:tensorflow:global_step/sec: 0.0344995\n","INFO:tensorflow:loss = 1.5264776, step = 9909 (28.981 sec)\n","INFO:tensorflow:global_step/sec: 0.0338291\n","INFO:tensorflow:loss = 1.5903027, step = 9910 (29.561 sec)\n","INFO:tensorflow:global_step/sec: 0.0340861\n","INFO:tensorflow:loss = 1.4203411, step = 9911 (29.337 sec)\n","INFO:tensorflow:global_step/sec: 0.0347987\n","INFO:tensorflow:loss = 1.5253438, step = 9912 (28.736 sec)\n","INFO:tensorflow:global_step/sec: 0.0343092\n","INFO:tensorflow:loss = 1.4649947, step = 9913 (29.151 sec)\n","INFO:tensorflow:global_step/sec: 0.0351291\n","INFO:tensorflow:loss = 1.5088961, step = 9914 (28.462 sec)\n","INFO:tensorflow:global_step/sec: 0.0342344\n","INFO:tensorflow:loss = 1.4481156, step = 9915 (29.211 sec)\n","INFO:tensorflow:global_step/sec: 0.0335709\n","INFO:tensorflow:loss = 1.3790401, step = 9916 (29.791 sec)\n","INFO:tensorflow:Saving checkpoints for 9917 into denseNet3d_result/model.ckpt.\n","INFO:tensorflow:global_step/sec: 0.0339478\n","INFO:tensorflow:loss = 1.4044752, step = 9917 (29.453 sec)\n","INFO:tensorflow:global_step/sec: 0.0337596\n","INFO:tensorflow:loss = 1.6217362, step = 9918 (29.622 sec)\n","INFO:tensorflow:global_step/sec: 0.0342889\n","INFO:tensorflow:loss = 1.6229694, step = 9919 (29.164 sec)\n","INFO:tensorflow:global_step/sec: 0.0338845\n","INFO:tensorflow:loss = 1.4977403, step = 9920 (29.513 sec)\n","INFO:tensorflow:global_step/sec: 0.0342063\n","INFO:tensorflow:loss = 1.3902357, step = 9921 (29.237 sec)\n","INFO:tensorflow:global_step/sec: 0.0339337\n","INFO:tensorflow:loss = 1.4156053, step = 9922 (29.467 sec)\n","INFO:tensorflow:global_step/sec: 0.034169\n","INFO:tensorflow:loss = 1.3581111, step = 9923 (29.266 sec)\n","INFO:tensorflow:global_step/sec: 0.0351207\n","INFO:tensorflow:loss = 1.6329491, step = 9924 (28.476 sec)\n","INFO:tensorflow:global_step/sec: 0.0342533\n","INFO:tensorflow:loss = 1.5870268, step = 9925 (29.191 sec)\n","INFO:tensorflow:global_step/sec: 0.0345261\n","INFO:tensorflow:loss = 1.4391987, step = 9926 (28.964 sec)\n","INFO:tensorflow:global_step/sec: 0.0338007\n","INFO:tensorflow:loss = 1.456588, step = 9927 (29.585 sec)\n","INFO:tensorflow:global_step/sec: 0.0339159\n","INFO:tensorflow:loss = 1.4259036, step = 9928 (29.485 sec)\n","INFO:tensorflow:global_step/sec: 0.033501\n","INFO:tensorflow:loss = 1.4668506, step = 9929 (29.850 sec)\n","INFO:tensorflow:global_step/sec: 0.0349968\n","INFO:tensorflow:loss = 1.6473553, step = 9930 (28.574 sec)\n","INFO:tensorflow:global_step/sec: 0.0340078\n","INFO:tensorflow:loss = 1.7374604, step = 9931 (29.405 sec)\n","INFO:tensorflow:global_step/sec: 0.0343692\n","INFO:tensorflow:loss = 1.5651398, step = 9932 (29.100 sec)\n","INFO:tensorflow:global_step/sec: 0.0339974\n","INFO:tensorflow:loss = 1.51448, step = 9933 (29.410 sec)\n","INFO:tensorflow:global_step/sec: 0.0337344\n","INFO:tensorflow:loss = 1.464047, step = 9934 (29.643 sec)\n","INFO:tensorflow:global_step/sec: 0.0352492\n","INFO:tensorflow:loss = 1.3842621, step = 9935 (28.371 sec)\n","INFO:tensorflow:global_step/sec: 0.0350214\n","INFO:tensorflow:loss = 1.4546815, step = 9936 (28.553 sec)\n","INFO:tensorflow:global_step/sec: 0.0350545\n","INFO:tensorflow:loss = 1.4839818, step = 9937 (28.528 sec)\n","INFO:tensorflow:Saving checkpoints for 9938 into denseNet3d_result/model.ckpt.\n","INFO:tensorflow:global_step/sec: 0.0345885\n","INFO:tensorflow:loss = 1.3937657, step = 9938 (28.909 sec)\n","INFO:tensorflow:global_step/sec: 0.0345983\n","INFO:tensorflow:loss = 1.3713424, step = 9939 (28.904 sec)\n","INFO:tensorflow:global_step/sec: 0.0343307\n","INFO:tensorflow:loss = 1.5736003, step = 9940 (29.129 sec)\n","INFO:tensorflow:global_step/sec: 0.0338324\n","INFO:tensorflow:loss = 1.4160155, step = 9941 (29.557 sec)\n","INFO:tensorflow:global_step/sec: 0.0344449\n","INFO:tensorflow:loss = 1.5702541, step = 9942 (29.032 sec)\n","INFO:tensorflow:global_step/sec: 0.0349264\n","INFO:tensorflow:loss = 1.5698262, step = 9943 (28.634 sec)\n","INFO:tensorflow:global_step/sec: 0.034151\n","INFO:tensorflow:loss = 1.4210455, step = 9944 (29.280 sec)\n","INFO:tensorflow:global_step/sec: 0.0344009\n","INFO:tensorflow:loss = 1.4627788, step = 9945 (29.069 sec)\n","INFO:tensorflow:global_step/sec: 0.0335581\n","INFO:tensorflow:loss = 1.5858977, step = 9946 (29.801 sec)\n","INFO:tensorflow:global_step/sec: 0.0331119\n","INFO:tensorflow:loss = 1.3092597, step = 9947 (30.198 sec)\n","INFO:tensorflow:global_step/sec: 0.0333471\n","INFO:tensorflow:loss = 1.4787948, step = 9948 (29.992 sec)\n","INFO:tensorflow:global_step/sec: 0.0340735\n","INFO:tensorflow:loss = 1.6091623, step = 9949 (29.350 sec)\n","INFO:tensorflow:global_step/sec: 0.0346905\n","INFO:tensorflow:loss = 1.668615, step = 9950 (28.824 sec)\n","INFO:tensorflow:global_step/sec: 0.0343365\n","INFO:tensorflow:loss = 1.6034801, step = 9951 (29.124 sec)\n","INFO:tensorflow:global_step/sec: 0.034568\n","INFO:tensorflow:loss = 1.4844369, step = 9952 (28.924 sec)\n","INFO:tensorflow:global_step/sec: 0.0341055\n","INFO:tensorflow:loss = 1.5526826, step = 9953 (29.323 sec)\n","INFO:tensorflow:global_step/sec: 0.0350686\n","INFO:tensorflow:loss = 1.4189942, step = 9954 (28.513 sec)\n","INFO:tensorflow:global_step/sec: 0.0336223\n","INFO:tensorflow:loss = 1.5336134, step = 9955 (29.742 sec)\n","INFO:tensorflow:global_step/sec: 0.0339829\n","INFO:tensorflow:loss = 1.53333, step = 9956 (29.427 sec)\n","INFO:tensorflow:global_step/sec: 0.0341345\n","INFO:tensorflow:loss = 1.3740523, step = 9957 (29.296 sec)\n","INFO:tensorflow:global_step/sec: 0.0334183\n","INFO:tensorflow:loss = 1.3026295, step = 9958 (29.928 sec)\n","INFO:tensorflow:Saving checkpoints for 9959 into denseNet3d_result/model.ckpt.\n","INFO:tensorflow:global_step/sec: 0.0338436\n","INFO:tensorflow:loss = 1.4447291, step = 9959 (29.546 sec)\n","INFO:tensorflow:global_step/sec: 0.0346198\n","INFO:tensorflow:loss = 1.3429121, step = 9960 (28.888 sec)\n","INFO:tensorflow:global_step/sec: 0.0346736\n","INFO:tensorflow:loss = 1.4393611, step = 9961 (28.835 sec)\n","INFO:tensorflow:global_step/sec: 0.0345827\n","INFO:tensorflow:loss = 1.405936, step = 9962 (28.916 sec)\n","INFO:tensorflow:global_step/sec: 0.034525\n","INFO:tensorflow:loss = 1.5101116, step = 9963 (28.965 sec)\n","INFO:tensorflow:global_step/sec: 0.0348397\n","INFO:tensorflow:loss = 1.5852804, step = 9964 (28.703 sec)\n","INFO:tensorflow:global_step/sec: 0.0341601\n","INFO:tensorflow:loss = 1.3790753, step = 9965 (29.274 sec)\n","INFO:tensorflow:global_step/sec: 0.0344698\n","INFO:tensorflow:loss = 1.6296651, step = 9966 (29.011 sec)\n","INFO:tensorflow:global_step/sec: 0.0347272\n","INFO:tensorflow:loss = 1.5506046, step = 9967 (28.796 sec)\n","INFO:tensorflow:global_step/sec: 0.0344755\n","INFO:tensorflow:loss = 1.3946877, step = 9968 (29.006 sec)\n","INFO:tensorflow:global_step/sec: 0.034259\n","INFO:tensorflow:loss = 1.4267199, step = 9969 (29.189 sec)\n","INFO:tensorflow:global_step/sec: 0.0350134\n","INFO:tensorflow:loss = 1.5521411, step = 9970 (28.560 sec)\n","INFO:tensorflow:global_step/sec: 0.0343698\n","INFO:tensorflow:loss = 1.5374278, step = 9971 (29.096 sec)\n","INFO:tensorflow:global_step/sec: 0.0346634\n","INFO:tensorflow:loss = 1.5217743, step = 9972 (28.849 sec)\n","INFO:tensorflow:global_step/sec: 0.034825\n","INFO:tensorflow:loss = 1.4915594, step = 9973 (28.719 sec)\n","INFO:tensorflow:global_step/sec: 0.034658\n","INFO:tensorflow:loss = 1.6554906, step = 9974 (28.849 sec)\n","INFO:tensorflow:global_step/sec: 0.0344346\n","INFO:tensorflow:loss = 1.3794172, step = 9975 (29.041 sec)\n","INFO:tensorflow:global_step/sec: 0.0356041\n","INFO:tensorflow:loss = 1.5533016, step = 9976 (28.086 sec)\n","INFO:tensorflow:global_step/sec: 0.0348016\n","INFO:tensorflow:loss = 1.5190824, step = 9977 (28.738 sec)\n","INFO:tensorflow:global_step/sec: 0.0344562\n","INFO:tensorflow:loss = 1.5267826, step = 9978 (29.019 sec)\n","INFO:tensorflow:global_step/sec: 0.0347606\n","INFO:tensorflow:loss = 1.5387894, step = 9979 (28.771 sec)\n","INFO:tensorflow:Saving checkpoints for 9980 into denseNet3d_result/model.ckpt.\n","INFO:tensorflow:global_step/sec: 0.0337712\n","INFO:tensorflow:loss = 1.5030363, step = 9980 (29.609 sec)\n","INFO:tensorflow:global_step/sec: 0.0350141\n","INFO:tensorflow:loss = 1.5827796, step = 9981 (28.560 sec)\n","INFO:tensorflow:global_step/sec: 0.0353681\n","INFO:tensorflow:loss = 1.5319989, step = 9982 (28.274 sec)\n","INFO:tensorflow:global_step/sec: 0.0352672\n","INFO:tensorflow:loss = 1.4483296, step = 9983 (28.361 sec)\n","INFO:tensorflow:global_step/sec: 0.0346126\n","INFO:tensorflow:loss = 1.5845735, step = 9984 (28.885 sec)\n","INFO:tensorflow:global_step/sec: 0.0341859\n","INFO:tensorflow:loss = 1.5056173, step = 9985 (29.252 sec)\n","INFO:tensorflow:global_step/sec: 0.0342542\n","INFO:tensorflow:loss = 1.5838678, step = 9986 (29.193 sec)\n","INFO:tensorflow:global_step/sec: 0.0356159\n","INFO:tensorflow:loss = 1.6891063, step = 9987 (28.077 sec)\n","INFO:tensorflow:global_step/sec: 0.0349923\n","INFO:tensorflow:loss = 1.5639517, step = 9988 (28.578 sec)\n","INFO:tensorflow:global_step/sec: 0.0343585\n","INFO:tensorflow:loss = 1.643253, step = 9989 (29.105 sec)\n","INFO:tensorflow:global_step/sec: 0.0352635\n","INFO:tensorflow:loss = 1.5155874, step = 9990 (28.358 sec)\n","INFO:tensorflow:global_step/sec: 0.0355018\n","INFO:tensorflow:loss = 1.4308693, step = 9991 (28.168 sec)\n","INFO:tensorflow:global_step/sec: 0.0346216\n","INFO:tensorflow:loss = 1.5672817, step = 9992 (28.883 sec)\n","INFO:tensorflow:global_step/sec: 0.0350965\n","INFO:tensorflow:loss = 1.3271241, step = 9993 (28.493 sec)\n","INFO:tensorflow:global_step/sec: 0.0348196\n","INFO:tensorflow:loss = 1.591672, step = 9994 (28.719 sec)\n","INFO:tensorflow:global_step/sec: 0.0345558\n","INFO:tensorflow:loss = 1.551058, step = 9995 (28.938 sec)\n","INFO:tensorflow:global_step/sec: 0.0349067\n","INFO:tensorflow:loss = 1.5463748, step = 9996 (28.655 sec)\n","INFO:tensorflow:global_step/sec: 0.0350178\n","INFO:tensorflow:loss = 1.5778253, step = 9997 (28.549 sec)\n","INFO:tensorflow:global_step/sec: 0.0348164\n","INFO:tensorflow:loss = 1.4245731, step = 9998 (28.722 sec)\n","INFO:tensorflow:global_step/sec: 0.0345311\n","INFO:tensorflow:loss = 1.5034993, step = 9999 (28.963 sec)\n","INFO:tensorflow:global_step/sec: 0.0344892\n","INFO:tensorflow:loss = 1.6245136, step = 10000 (28.994 sec)\n","INFO:tensorflow:Saving checkpoints for 10001 into denseNet3d_result/model.ckpt.\n","INFO:tensorflow:global_step/sec: 0.0343335\n","INFO:tensorflow:loss = 1.4884151, step = 10001 (29.126 sec)\n","INFO:tensorflow:global_step/sec: 0.0344511\n","INFO:tensorflow:loss = 1.5430386, step = 10002 (29.025 sec)\n","INFO:tensorflow:global_step/sec: 0.0350697\n","INFO:tensorflow:loss = 1.5414263, step = 10003 (28.515 sec)\n","INFO:tensorflow:global_step/sec: 0.0347064\n","INFO:tensorflow:loss = 1.5220114, step = 10004 (28.816 sec)\n","INFO:tensorflow:global_step/sec: 0.0347191\n","INFO:tensorflow:loss = 1.6089182, step = 10005 (28.800 sec)\n","INFO:tensorflow:global_step/sec: 0.0345348\n","INFO:tensorflow:loss = 1.4878132, step = 10006 (28.956 sec)\n","INFO:tensorflow:global_step/sec: 0.0341431\n","INFO:tensorflow:loss = 1.6181269, step = 10007 (29.293 sec)\n","INFO:tensorflow:global_step/sec: 0.0341935\n","INFO:tensorflow:loss = 1.4740685, step = 10008 (29.244 sec)\n","INFO:tensorflow:global_step/sec: 0.0348735\n","INFO:tensorflow:loss = 1.4260305, step = 10009 (28.671 sec)\n","INFO:tensorflow:global_step/sec: 0.0349678\n","INFO:tensorflow:loss = 1.5344317, step = 10010 (28.606 sec)\n","INFO:tensorflow:global_step/sec: 0.0346249\n","INFO:tensorflow:loss = 1.6114995, step = 10011 (28.873 sec)\n","INFO:tensorflow:global_step/sec: 0.0346634\n","INFO:tensorflow:loss = 1.4498354, step = 10012 (28.849 sec)\n","INFO:tensorflow:global_step/sec: 0.0344007\n","INFO:tensorflow:loss = 1.5845362, step = 10013 (29.070 sec)\n","INFO:tensorflow:global_step/sec: 0.0344452\n","INFO:tensorflow:loss = 1.6486557, step = 10014 (29.030 sec)\n","INFO:tensorflow:global_step/sec: 0.0344678\n","INFO:tensorflow:loss = 1.577501, step = 10015 (29.013 sec)\n","INFO:tensorflow:global_step/sec: 0.0344138\n","INFO:tensorflow:loss = 1.688317, step = 10016 (29.062 sec)\n","INFO:tensorflow:global_step/sec: 0.0353849\n","INFO:tensorflow:loss = 1.4324242, step = 10017 (28.261 sec)\n","INFO:tensorflow:global_step/sec: 0.03547\n","INFO:tensorflow:loss = 1.5494188, step = 10018 (28.192 sec)\n","INFO:tensorflow:global_step/sec: 0.0345954\n","INFO:tensorflow:loss = 1.434303, step = 10019 (28.903 sec)\n","INFO:tensorflow:global_step/sec: 0.0345492\n","INFO:tensorflow:loss = 1.389184, step = 10020 (28.944 sec)\n","INFO:tensorflow:global_step/sec: 0.0350019\n","INFO:tensorflow:loss = 1.4225184, step = 10021 (28.570 sec)\n","INFO:tensorflow:Saving checkpoints for 10022 into denseNet3d_result/model.ckpt.\n","INFO:tensorflow:global_step/sec: 0.0357625\n","INFO:tensorflow:loss = 1.6000162, step = 10022 (27.962 sec)\n","INFO:tensorflow:global_step/sec: 0.0355334\n","INFO:tensorflow:loss = 1.402433, step = 10023 (28.143 sec)\n","INFO:tensorflow:global_step/sec: 0.034805\n","INFO:tensorflow:loss = 1.5003793, step = 10024 (28.733 sec)\n","INFO:tensorflow:global_step/sec: 0.0357109\n","INFO:tensorflow:loss = 1.437999, step = 10025 (28.002 sec)\n","INFO:tensorflow:global_step/sec: 0.0351839\n","INFO:tensorflow:loss = 1.6411308, step = 10026 (28.421 sec)\n","INFO:tensorflow:global_step/sec: 0.0349137\n","INFO:tensorflow:loss = 1.5012871, step = 10027 (28.642 sec)\n","INFO:tensorflow:global_step/sec: 0.035143\n","INFO:tensorflow:loss = 1.518507, step = 10028 (28.457 sec)\n","INFO:tensorflow:global_step/sec: 0.0346097\n","INFO:tensorflow:loss = 1.496476, step = 10029 (28.892 sec)\n","INFO:tensorflow:global_step/sec: 0.0351497\n","INFO:tensorflow:loss = 1.4688907, step = 10030 (28.450 sec)\n","INFO:tensorflow:global_step/sec: 0.0350306\n","INFO:tensorflow:loss = 1.4465733, step = 10031 (28.551 sec)\n","INFO:tensorflow:global_step/sec: 0.0342399\n","INFO:tensorflow:loss = 1.4892845, step = 10032 (29.201 sec)\n","INFO:tensorflow:global_step/sec: 0.0348439\n","INFO:tensorflow:loss = 1.480836, step = 10033 (28.702 sec)\n","INFO:tensorflow:global_step/sec: 0.0352377\n","INFO:tensorflow:loss = 1.4749943, step = 10034 (28.376 sec)\n","INFO:tensorflow:global_step/sec: 0.0348432\n","INFO:tensorflow:loss = 1.4167302, step = 10035 (28.700 sec)\n","INFO:tensorflow:global_step/sec: 0.0345899\n","INFO:tensorflow:loss = 1.5579998, step = 10036 (28.914 sec)\n","INFO:tensorflow:global_step/sec: 0.0348515\n","INFO:tensorflow:loss = 1.440896, step = 10037 (28.688 sec)\n","INFO:tensorflow:global_step/sec: 0.0350095\n","INFO:tensorflow:loss = 1.487642, step = 10038 (28.563 sec)\n","INFO:tensorflow:global_step/sec: 0.0346827\n","INFO:tensorflow:loss = 1.5339459, step = 10039 (28.833 sec)\n","INFO:tensorflow:global_step/sec: 0.0350298\n","INFO:tensorflow:loss = 1.5279583, step = 10040 (28.548 sec)\n","INFO:tensorflow:global_step/sec: 0.0343942\n","INFO:tensorflow:loss = 1.6131827, step = 10041 (29.076 sec)\n","INFO:tensorflow:global_step/sec: 0.0347046\n","INFO:tensorflow:loss = 1.539912, step = 10042 (28.813 sec)\n","INFO:tensorflow:Saving checkpoints for 10043 into denseNet3d_result/model.ckpt.\n","INFO:tensorflow:global_step/sec: 0.0342266\n","INFO:tensorflow:loss = 1.5289654, step = 10043 (29.217 sec)\n","INFO:tensorflow:global_step/sec: 0.0350133\n","INFO:tensorflow:loss = 1.3417774, step = 10044 (28.565 sec)\n","INFO:tensorflow:global_step/sec: 0.0350163\n","INFO:tensorflow:loss = 1.3822156, step = 10045 (28.554 sec)\n","INFO:tensorflow:global_step/sec: 0.0354558\n","INFO:tensorflow:loss = 1.506263, step = 10046 (28.209 sec)\n","INFO:tensorflow:global_step/sec: 0.0355759\n","INFO:tensorflow:loss = 1.5225532, step = 10047 (28.104 sec)\n","INFO:tensorflow:global_step/sec: 0.0344078\n","INFO:tensorflow:loss = 1.4443331, step = 10048 (29.064 sec)\n","INFO:tensorflow:global_step/sec: 0.0350357\n","INFO:tensorflow:loss = 1.5202696, step = 10049 (28.542 sec)\n","INFO:tensorflow:global_step/sec: 0.0348929\n","INFO:tensorflow:loss = 1.6045309, step = 10050 (28.658 sec)\n","INFO:tensorflow:global_step/sec: 0.0348473\n","INFO:tensorflow:loss = 1.601491, step = 10051 (28.701 sec)\n","INFO:tensorflow:global_step/sec: 0.0349436\n","INFO:tensorflow:loss = 1.5677698, step = 10052 (28.613 sec)\n","INFO:tensorflow:global_step/sec: 0.0348654\n","INFO:tensorflow:loss = 1.6631486, step = 10053 (28.682 sec)\n","INFO:tensorflow:global_step/sec: 0.0340673\n","INFO:tensorflow:loss = 1.3790239, step = 10054 (29.361 sec)\n","INFO:tensorflow:global_step/sec: 0.0351076\n","INFO:tensorflow:loss = 1.5839612, step = 10055 (28.477 sec)\n","INFO:tensorflow:global_step/sec: 0.0356635\n","INFO:tensorflow:loss = 1.5279939, step = 10056 (28.040 sec)\n","INFO:tensorflow:global_step/sec: 0.0347464\n","INFO:tensorflow:loss = 1.3306878, step = 10057 (28.785 sec)\n","INFO:tensorflow:global_step/sec: 0.0348227\n","INFO:tensorflow:loss = 1.3665025, step = 10058 (28.711 sec)\n","INFO:tensorflow:global_step/sec: 0.0349827\n","INFO:tensorflow:loss = 1.3937385, step = 10059 (28.586 sec)\n","INFO:tensorflow:global_step/sec: 0.0342099\n","INFO:tensorflow:loss = 1.5995194, step = 10060 (29.232 sec)\n","INFO:tensorflow:Saving checkpoints for 10060 into denseNet3d_result/model.ckpt.\n","INFO:tensorflow:Loss for final step: 1.5995194.\n","INFO:tensorflow:Calling model_fn.\n","Build 3D DenseNet-BC model with 3 blocks, 2 bottleneck layers and 2 composite layers each.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2019-07-16-22:47:45\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from denseNet3d_result/model.ckpt-10060\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Evaluation [10/100]\n","INFO:tensorflow:Evaluation [20/100]\n","INFO:tensorflow:Evaluation [30/100]\n","INFO:tensorflow:Evaluation [40/100]\n","INFO:tensorflow:Evaluation [50/100]\n","INFO:tensorflow:Evaluation [60/100]\n","INFO:tensorflow:Evaluation [70/100]\n","INFO:tensorflow:Evaluation [80/100]\n","INFO:tensorflow:Evaluation [90/100]\n","INFO:tensorflow:Evaluation [100/100]\n","INFO:tensorflow:Finished evaluation at 2019-07-16-23:03:35\n","INFO:tensorflow:Saving dict for global step 10060: eval_accuracy = 0.3215, global_step = 10060, loss = 1.5700167\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10060: denseNet3d_result/model.ckpt-10060\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'eval_accuracy': 0.3215, 'global_step': 10060, 'loss': 1.5700167}"]},"metadata":{"tags":[]},"execution_count":7}]}]}